{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uqXuwPhsl_vY"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "# üì¶ Install required packages\n",
        "!pip install transformers==4.36.0\n",
        "!pip install torch\n",
        "!pip install datasets\n",
        "!pip install accelerate\n",
        "!pip install bitsandbytes\n",
        "!pip install peft\n",
        "!pip install trl\n",
        "!pip install wandb\n",
        "!pip install scipy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "r210KG0mmFV5"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install --upgrade transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7vhAwIpmHHZ",
        "outputId": "4ad95b6e-f92a-4307-b7a1-fe45740f751e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Attempting to remount Google Drive...\n",
            "Mounted at /content/drive\n",
            "Google Drive remount initiated. Please check for verification prompt if any.\n",
            "üöÄ Starting A100-Optimized DPO Training Setup...\n",
            "üì± Device: cuda\n",
            "üß† GPU Memory: 42.5 GB\n",
            "üî• GPU Name: NVIDIA A100-SXM4-40GB\n",
            "‚úÖ Fine-tuned model found at: /content/drive/MyDrive/llama_31_therapist_outputs/llama31_merged_v104952\n",
            "üìÅ Model files found: 4\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForCausalLM,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    BitsAndBytesConfig\n",
        ")\n",
        "from datasets import Dataset, load_dataset\n",
        "from peft import (\n",
        "    LoraConfig,\n",
        "    get_peft_model,\n",
        "    TaskType,\n",
        "    PeftModel\n",
        ")\n",
        "from trl import DPOTrainer  # CHANGED: Removed PPO imports, added DPO\n",
        "import wandb\n",
        "\n",
        "# üîß A100-Optimized Configuration for DPO\n",
        "class DPOConfig:  # CHANGED: Renamed from RLHFConfig\n",
        "    def __init__(self):\n",
        "        # Model paths - UPDATED to match new directory structure\n",
        "        self.base_model = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "        self.fine_tuned_model_path = \"/content/drive/MyDrive/llama_31_therapist_outputs/llama31_merged_v104952\"\n",
        "        self.dataset_name = \"Psychotherapy-LLM/PsychoCounsel-Preference\"\n",
        "\n",
        "        # A100 Optimized Training parameters for DPO\n",
        "        self.batch_size = 1\n",
        "        self.learning_rate = 1.4e-5\n",
        "        self.max_length = 512\n",
        "        self.max_prompt_length = 256\n",
        "        self.gradient_accumulation_steps = 8\n",
        "        self.num_train_epochs = 3\n",
        "        self.save_steps = 50  # More frequent saves\n",
        "        self.logging_steps = 5  # More frequent logging\n",
        "        self.beta = 0.1  # ADDED: DPO beta parameter\n",
        "\n",
        "        # Output directory - UPDATED for DPO\n",
        "        self.output_dir = \"/content/drive/MyDrive/llama_31_therapist_outputs/dpo_therapy_model\"\n",
        "\n",
        "        # Device\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "        # Weights & Biases logging\n",
        "        self.use_wandb = True\n",
        "\n",
        "config = DPOConfig()  # CHANGED: Updated class name\n",
        "\n",
        "from google.colab import drive\n",
        "print(\"Attempting to remount Google Drive...\")\n",
        "drive.mount('/content/drive', force_remount=True) # force_remount can help with stale mounts\n",
        "print(\"Google Drive remount initiated. Please check for verification prompt if any.\")\n",
        "\n",
        "print(\"üöÄ Starting A100-Optimized DPO Training Setup...\")  # CHANGED: Updated message\n",
        "print(f\"üì± Device: {config.device}\")\n",
        "print(f\"üß† GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "print(f\"üî• GPU Name: {torch.cuda.get_device_properties(0).name}\")\n",
        "\n",
        "# Verify the fine-tuned model path exists\n",
        "if os.path.exists(config.fine_tuned_model_path):\n",
        "    print(f\"‚úÖ Fine-tuned model found at: {config.fine_tuned_model_path}\")\n",
        "    # Check for model files\n",
        "    model_files = [f for f in os.listdir(config.fine_tuned_model_path) if f.endswith(('.safetensors', '.bin'))]\n",
        "    print(f\"üìÅ Model files found: {len(model_files)}\")\n",
        "else:\n",
        "    print(f\"‚ùå Fine-tuned model NOT found at: {config.fine_tuned_model_path}\")\n",
        "    print(\"Please check the path or complete the initial fine-tuning first.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "F5vr5cWymI2W"
      },
      "outputs": [],
      "source": [
        "def load_preference_dataset():\n",
        "    \"\"\"Load and preprocess the preference dataset for DPO\"\"\"\n",
        "    print(\"üìö Loading PsychoCounsel preference dataset for DPO...\")\n",
        "\n",
        "    try:\n",
        "        dataset = load_dataset(config.dataset_name)\n",
        "\n",
        "        # Check if train split exists, otherwise use available split\n",
        "        if 'train' in dataset:\n",
        "            train_dataset = dataset['train']\n",
        "        else:\n",
        "            # Use the first available split\n",
        "            available_splits = list(dataset.keys())\n",
        "            print(f\"‚ö†Ô∏è No 'train' split found. Available splits: {available_splits}\")\n",
        "            train_dataset = dataset[available_splits[0]]\n",
        "            print(f\"üìä Using '{available_splits[0]}' split instead\")\n",
        "\n",
        "        print(f\"üìä Dataset columns: {train_dataset.column_names}\")\n",
        "        print(f\"üìä Dataset size: {len(train_dataset)}\")\n",
        "\n",
        "        # CHANGED: DPO needs prompt, chosen, rejected - keep all three\n",
        "        def format_data_for_dpo(examples):\n",
        "            return {\n",
        "                'prompt': examples['question'],    # The question/prompt\n",
        "                'chosen': examples['chosen'],      # Preferred response\n",
        "                'rejected': examples['rejected']   # Less preferred response\n",
        "            }\n",
        "\n",
        "        formatted_dataset = train_dataset.map(\n",
        "            format_data_for_dpo,\n",
        "            batched=True,\n",
        "            # CHANGED: Don't remove columns, DPO needs chosen/rejected\n",
        "        )\n",
        "\n",
        "        print(f\"‚úÖ Dataset loaded and formatted for DPO: {len(formatted_dataset)} examples\")\n",
        "\n",
        "        # ADDED: Randomly sample 3500 examples for faster training\n",
        "        if len(formatted_dataset) > 3500:\n",
        "            formatted_dataset = formatted_dataset.shuffle(seed=42).select(range(3500))\n",
        "            print(f\"üöÄ Using random subset of {len(formatted_dataset)} examples for faster training\")\n",
        "        else:\n",
        "            print(f\"üöÄ Using full dataset of {len(formatted_dataset)} examples\")\n",
        "\n",
        "        # Show a sample to verify format\n",
        "        if len(formatted_dataset) > 0:\n",
        "            print(f\"üìù Sample prompt: {formatted_dataset[0]['prompt'][:100]}...\")\n",
        "            print(f\"üìù Sample chosen: {formatted_dataset[0]['chosen'][:100]}...\")\n",
        "            print(f\"üìù Sample rejected: {formatted_dataset[0]['rejected'][:100]}...\")\n",
        "\n",
        "        return formatted_dataset\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error loading dataset: {e}\")\n",
        "        print(f\"üîç Dataset name attempted: {config.dataset_name}\")\n",
        "\n",
        "        # CHANGED: Fallback data for DPO (create sample chosen/rejected pairs)\n",
        "        print(\"üîÑ Creating sample DPO dataset...\")\n",
        "        sample_data = []\n",
        "\n",
        "        sample_prompts = [\n",
        "            \"I've been feeling really anxious lately and can't seem to calm down. What should I do?\",\n",
        "            \"I'm having trouble sleeping and my mind keeps racing at night.\",\n",
        "            \"I feel like I'm not good enough and constantly compare myself to others.\",\n",
        "            \"I'm going through a difficult breakup and feel lost.\",\n",
        "            \"I'm struggling with work-life balance and feel burned out.\",\n",
        "            \"How can I manage my panic attacks better?\",\n",
        "            \"I feel disconnected from my friends and family.\",\n",
        "            \"I'm dealing with imposter syndrome at work.\",\n",
        "            \"I can't seem to motivate myself to do anything.\",\n",
        "            \"I'm having intrusive thoughts that worry me.\",\n",
        "        ]\n",
        "\n",
        "        # Create chosen/rejected pairs for each prompt\n",
        "        for prompt in sample_prompts:\n",
        "            sample_data.append({\n",
        "                'prompt': prompt,\n",
        "                'chosen': f\"I understand you're going through a difficult time with {prompt.split()[4:8]}. It's completely normal to feel this way, and I want you to know that you're not alone. Let's work together to explore some strategies that might help you feel better. Can you tell me more about when these feelings are strongest?\",\n",
        "                'rejected': f\"That sounds tough. You should probably just try to relax and not think about it too much. Maybe try some deep breathing or something.\"\n",
        "            })\n",
        "\n",
        "        # Extend for more training data\n",
        "        extended_data = sample_data * 5  # 50 examples total\n",
        "        sample_dataset = Dataset.from_list(extended_data)\n",
        "\n",
        "        print(f\"‚úÖ Sample DPO dataset created: {len(sample_dataset)} examples\")\n",
        "        return sample_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "47FPDoOWnD5v"
      },
      "outputs": [],
      "source": [
        "def load_fine_tuned_model():\n",
        "    \"\"\"Load your fine-tuned therapy model - A100 optimized for DPO\"\"\"\n",
        "    print(\"ü¶ô Loading fine-tuned Llama 3.1 therapy model for DPO (A100 optimized)...\")\n",
        "\n",
        "    # A100-optimized quantization config (less aggressive for better quality)\n",
        "    quantization_config = BitsAndBytesConfig(\n",
        "        load_in_4bit=True,\n",
        "        bnb_4bit_compute_dtype=torch.bfloat16,  # Use bfloat16 for A100\n",
        "        bnb_4bit_use_double_quant=True,\n",
        "        bnb_4bit_quant_type=\"nf4\"\n",
        "    )\n",
        "\n",
        "    # quantization_config = None  # No quantization for highest quality (requires ~16GB VRAM)\n",
        "\n",
        "    try:\n",
        "        # Load tokenizer\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\n",
        "            config.fine_tuned_model_path,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        # Load model - Flash Attention disabled for compatibility\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            config.fine_tuned_model_path,\n",
        "            quantization_config=quantization_config,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.bfloat16,  # Use bfloat16 for A100\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ Fine-tuned model loaded successfully with A100 optimizations!\")\n",
        "        print(f\"üìä Model device: {model.device}\")\n",
        "        print(f\"üß† Model dtype: {model.dtype}\")\n",
        "        print(\"üîß Ready for DPO training!\")\n",
        "\n",
        "        return model, tokenizer\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è  Error loading fine-tuned model: {e}\")\n",
        "        print(\"üîÑ Falling back to base model...\")\n",
        "\n",
        "        # Fallback to base model\n",
        "        tokenizer = AutoTokenizer.from_pretrained(\n",
        "            config.base_model,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "        if tokenizer.pad_token is None:\n",
        "            tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            config.base_model,\n",
        "            quantization_config=quantization_config,\n",
        "            device_map=\"auto\",\n",
        "            torch_dtype=torch.bfloat16,\n",
        "            trust_remote_code=True\n",
        "        )\n",
        "\n",
        "        print(\"‚ö†Ô∏è  Using base model instead of fine-tuned model\")\n",
        "        print(\"üîß Ready for DPO training with base model\")\n",
        "        return model, tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "xnoHTdIynM71"
      },
      "outputs": [],
      "source": [
        "def setup_dpo_training():\n",
        "    \"\"\"Setup DPO training configuration - A100 optimized\"\"\"\n",
        "    print(\"üöÄ Setting up A100-optimized DPO training...\")\n",
        "\n",
        "    # Initialize wandb FIRST\n",
        "    if config.use_wandb:\n",
        "        try:\n",
        "            # Login to wandb (replace with your actual token)\n",
        "            wandb.login(key=\"533e36a3654f7c3301150fe947ee1b5cfe62c96b\")\n",
        "            print(\"‚úÖ wandb login successful\")\n",
        "\n",
        "            wandb.init(\n",
        "                project=\"llama-therapy-dpo\",\n",
        "                name=f\"dpo-training-{datetime.now().strftime('%Y%m%d-%H%M%S')}\",\n",
        "                config={\n",
        "                    \"base_model\": config.base_model,\n",
        "                    \"fine_tuned_model_path\": config.fine_tuned_model_path,\n",
        "                    \"batch_size\": config.batch_size,\n",
        "                    \"learning_rate\": config.learning_rate,\n",
        "                    \"max_length\": config.max_length,\n",
        "                    \"max_prompt_length\": config.max_prompt_length,\n",
        "                    \"gradient_accumulation_steps\": config.gradient_accumulation_steps,\n",
        "                    \"num_train_epochs\": config.num_train_epochs,\n",
        "                    \"lora_r\": 32,\n",
        "                    \"lora_alpha\": 64,\n",
        "                    \"beta\": config.beta,\n",
        "                },\n",
        "                tags=[\"dpo\", \"therapy\", \"llama-3.1\", \"a100\"]\n",
        "            )\n",
        "            print(\"‚úÖ wandb initialized successfully\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è wandb setup failed: {e}\")\n",
        "            config.use_wandb = False\n",
        "\n",
        "    # Load model and dataset\n",
        "    print(\"üìö Loading model and dataset...\")\n",
        "    model, tokenizer = load_fine_tuned_model()\n",
        "    dataset = load_preference_dataset()\n",
        "\n",
        "    # Split dataset for training and evaluation\n",
        "    print(\"üîÑ Splitting dataset for train/eval...\")\n",
        "    train_test_split = dataset.train_test_split(test_size=0.1, seed=42)\n",
        "    train_dataset = train_test_split['train']\n",
        "    eval_dataset = train_test_split['test']\n",
        "\n",
        "    print(f\"üìä Train dataset: {len(train_dataset)} examples\")\n",
        "    print(f\"üìä Eval dataset: {len(eval_dataset)} examples\")\n",
        "\n",
        "    # A100-optimized LoRA configuration\n",
        "    lora_config = LoraConfig(\n",
        "        r=32,\n",
        "        lora_alpha=64,\n",
        "        target_modules=[\n",
        "            \"q_proj\", \"v_proj\", \"k_proj\", \"o_proj\",\n",
        "            \"gate_proj\", \"up_proj\", \"down_proj\"\n",
        "        ],\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        task_type=TaskType.CAUSAL_LM,\n",
        "    )\n",
        "\n",
        "    print(\"üéØ Setting up DPO configuration...\")\n",
        "\n",
        "    try:\n",
        "        from trl import DPOConfig\n",
        "\n",
        "        dpo_config = DPOConfig(\n",
        "            output_dir=config.output_dir,\n",
        "            learning_rate=config.learning_rate,\n",
        "            per_device_train_batch_size=config.batch_size,\n",
        "            per_device_eval_batch_size=config.batch_size,\n",
        "            gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
        "            num_train_epochs=config.num_train_epochs,\n",
        "            logging_steps=config.logging_steps,\n",
        "            save_steps=config.save_steps,\n",
        "            eval_steps=config.save_steps,\n",
        "            bf16=True,\n",
        "            remove_unused_columns=False,\n",
        "            report_to=\"wandb\" if config.use_wandb else None,\n",
        "            dataloader_drop_last=True,\n",
        "            eval_strategy=\"steps\",\n",
        "            save_strategy=\"steps\",\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            greater_is_better=False,\n",
        "            save_total_limit=3,\n",
        "        )\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Using TrainingArguments fallback: {e}\")\n",
        "        # Fallback to TrainingArguments if DPOConfig doesn't work\n",
        "        dpo_config = TrainingArguments(\n",
        "            output_dir=config.output_dir,\n",
        "            learning_rate=config.learning_rate,\n",
        "            per_device_train_batch_size=config.batch_size,\n",
        "            per_device_eval_batch_size=config.batch_size,\n",
        "            gradient_accumulation_steps=config.gradient_accumulation_steps,\n",
        "            num_train_epochs=config.num_train_epochs,\n",
        "            logging_steps=config.logging_steps,\n",
        "            save_steps=config.save_steps,\n",
        "            eval_steps=config.save_steps,\n",
        "            bf16=True,\n",
        "            remove_unused_columns=False,\n",
        "            report_to=\"wandb\" if config.use_wandb else None,\n",
        "            dataloader_drop_last=True,\n",
        "            eval_strategy=\"steps\",\n",
        "            save_strategy=\"steps\",\n",
        "            load_best_model_at_end=True,\n",
        "            metric_for_best_model=\"eval_loss\",\n",
        "            greater_is_better=False,\n",
        "            save_total_limit=3,\n",
        "        )\n",
        "\n",
        "    print(\"üèãÔ∏è Initializing DPO trainer...\")\n",
        "\n",
        "    # Initialize DPO trainer with CORRECT TRL 0.19.0 signature\n",
        "    try:\n",
        "        dpo_trainer = DPOTrainer(\n",
        "            model=model,                        # main model\n",
        "            ref_model=None,                     # DPO creates reference model automatically\n",
        "            args=dpo_config,                    # DPO configuration (not TrainingArguments)\n",
        "            train_dataset=train_dataset,        # training dataset\n",
        "            eval_dataset=eval_dataset,          # evaluation dataset\n",
        "            processing_class=tokenizer,         # tokenizer (called processing_class!)\n",
        "            peft_config=lora_config,            # LoRA configuration\n",
        "        )\n",
        "\n",
        "        print(\"‚úÖ DPO trainer initialized successfully!\")\n",
        "        print(f\"üìä Training dataset size: {len(train_dataset)}\")\n",
        "        print(f\"üìä Evaluation dataset size: {len(eval_dataset)}\")\n",
        "        print(f\"üéØ Batch size: {config.batch_size}\")\n",
        "        print(f\"üìè Max sequence length: {config.max_length}\")\n",
        "        print(f\"üé≤ Beta parameter: {config.beta}\")\n",
        "        print(f\"üìà Evaluation every {config.save_steps} steps\")\n",
        "\n",
        "        # Log additional info to wandb after successful initialization\n",
        "        if config.use_wandb:\n",
        "            wandb.log({\n",
        "                \"model/num_parameters\": sum(p.numel() for p in model.parameters()),\n",
        "                \"model/trainable_parameters\": sum(p.numel() for p in model.parameters() if p.requires_grad),\n",
        "                \"data/dataset_size\": len(train_dataset) + len(eval_dataset),\n",
        "                \"system/gpu_name\": torch.cuda.get_device_properties(0).name,\n",
        "                \"system/gpu_memory_gb\": torch.cuda.get_device_properties(0).total_memory / 1e9,\n",
        "            })\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error initializing DPO trainer: {e}\")\n",
        "        if config.use_wandb:\n",
        "            wandb.finish()\n",
        "        raise\n",
        "\n",
        "    return dpo_trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "NYg5QTQWnRP1"
      },
      "outputs": [],
      "source": [
        "def run_dpo_training():\n",
        "    \"\"\"Main DPO training loop - A100 optimized\"\"\"\n",
        "    print(\"üéì Starting A100-Optimized DPO Training...\")\n",
        "\n",
        "    # Setup training (much simpler than PPO!)\n",
        "    dpo_trainer = setup_dpo_training()\n",
        "\n",
        "    # Create output directory\n",
        "    os.makedirs(config.output_dir, exist_ok=True)\n",
        "\n",
        "    print(\"üöÄ Starting DPO training...\")\n",
        "\n",
        "    try:\n",
        "        # DPO training is much simpler - just call train()!\n",
        "        training_result = dpo_trainer.train()\n",
        "\n",
        "        print(\"‚úÖ DPO training completed successfully!\")\n",
        "\n",
        "        # Save the final model\n",
        "        print(\"üíæ Saving final model...\")\n",
        "        dpo_trainer.save_model()\n",
        "\n",
        "        # Save tokenizer\n",
        "        dpo_trainer.tokenizer.save_pretrained(config.output_dir)\n",
        "\n",
        "        # Log final metrics\n",
        "        if config.use_wandb:\n",
        "            final_metrics = {\n",
        "                \"training/final_loss\": training_result.training_loss,\n",
        "                \"training/total_steps\": training_result.global_step,\n",
        "            }\n",
        "            wandb.log(final_metrics)\n",
        "            wandb.finish()\n",
        "            print(\"‚úÖ wandb logging completed\")\n",
        "\n",
        "        print(f\"üéâ DPO Training completed!\")\n",
        "        print(f\"üìä Final training loss: {training_result.training_loss:.4f}\")\n",
        "        print(f\"üìà Total training steps: {training_result.global_step}\")\n",
        "        print(f\"üíæ Model saved to: {config.output_dir}\")\n",
        "\n",
        "        return training_result\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during DPO training: {e}\")\n",
        "        if config.use_wandb:\n",
        "            wandb.finish()\n",
        "        raise\n",
        "\n",
        "# MUCH SIMPLER ALTERNATIVE: You can also just use the trainer directly\n",
        "def simple_dpo_training():\n",
        "    \"\"\"Even simpler DPO training - just the essentials\"\"\"\n",
        "    print(\"üéØ Simple DPO Training...\")\n",
        "\n",
        "    # Setup\n",
        "    trainer = setup_dpo_training()\n",
        "\n",
        "    # Train (that's it!)\n",
        "    trainer.train()\n",
        "\n",
        "    # Save\n",
        "    trainer.save_model()\n",
        "\n",
        "    print(\"‚úÖ Done!\")\n",
        "    return trainer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "7wygQMHTnYih"
      },
      "outputs": [],
      "source": [
        "def test_dpo_model():\n",
        "    \"\"\"Test the DPO trained model using NickyNicky dataset - A100 optimized\"\"\"\n",
        "    print(\"üß™ Testing A100-Optimized DPO model with NickyNicky/nlp-mental-health-conversations...\")\n",
        "\n",
        "    # Load the DPO trained model\n",
        "    model_path = config.output_dir  # DPO saves directly to output_dir\n",
        "\n",
        "    if not os.path.exists(model_path):\n",
        "        print(\"‚ùå No trained DPO model found!\")\n",
        "        return []\n",
        "\n",
        "    print(f\"üìÇ Loading DPO model from: {model_path}\")\n",
        "\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "        model = AutoModelForCausalLM.from_pretrained(\n",
        "            model_path,\n",
        "            torch_dtype=torch.bfloat16,  # A100 optimized\n",
        "            device_map=\"auto\"\n",
        "        )\n",
        "\n",
        "        # Load the same testing dataset\n",
        "        print(\"üìö Loading NickyNicky/nlp-mental-health-conversations for comparison...\")\n",
        "        try:\n",
        "            test_dataset = load_dataset(\"NickyNicky/nlp-mental-health-conversations\")\n",
        "            test_data = test_dataset['train']\n",
        "\n",
        "            # Test on more examples with A100 power\n",
        "            test_size = min(100, len(test_data))  # Increased to 100 examples\n",
        "            test_subset = test_data.select(range(test_size))\n",
        "\n",
        "            print(f\"üìä Testing on {test_size} examples from NickyNicky dataset\")\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading NickyNicky dataset: {e}\")\n",
        "            print(\"üîÑ Using fallback test queries...\")\n",
        "            test_queries = [\n",
        "                \"I'm feeling overwhelmed with anxiety. Can you help me?\",\n",
        "                \"I've been having trouble sleeping due to stress.\",\n",
        "                \"I feel like I'm not making progress in therapy.\",\n",
        "                \"I'm struggling with depression and feel hopeless.\",\n",
        "                \"How can I cope with panic attacks?\",\n",
        "                \"I'm having relationship problems and don't know what to do.\",\n",
        "                \"I feel like I'm not good enough and have low self-esteem.\",\n",
        "                \"I'm dealing with grief after losing someone close to me.\",\n",
        "                \"I'm having trouble managing my anger\",\n",
        "                \"I feel lonely and isolated from others\",\n",
        "                \"I can't seem to focus on anything lately\",\n",
        "                \"I'm worried about my future and career\",\n",
        "                \"I feel like I'm always disappointing people\",\n",
        "                \"I'm struggling with body image issues\",\n",
        "                \"I have trouble setting boundaries with others\"\n",
        "            ]\n",
        "            test_subset = [{\"text\": query} for query in test_queries]\n",
        "\n",
        "        results = []\n",
        "\n",
        "        # Process in batches for A100 efficiency\n",
        "        batch_size = 4\n",
        "\n",
        "        for i in range(0, len(test_subset), batch_size):\n",
        "            batch = test_subset[i:i+batch_size]\n",
        "\n",
        "            for j, example in enumerate(batch):\n",
        "                example_idx = i + j\n",
        "\n",
        "                # Extract the query/prompt from the dataset\n",
        "                if isinstance(example, dict):\n",
        "                    query = example.get('text', example.get('prompt', example.get('input', str(example))))\n",
        "                else:\n",
        "                    query = str(example)\n",
        "\n",
        "                # Limit query length\n",
        "                if len(query) > 300:\n",
        "                    query = query[:300] + \"...\"\n",
        "\n",
        "                print(f\"\\nüîÑ Processing example {example_idx+1}/{len(test_subset)}\")\n",
        "                print(f\"üí¨ Query: {query[:100]}...\")\n",
        "\n",
        "                # Generate response\n",
        "                inputs = tokenizer.encode(\n",
        "                    query,\n",
        "                    return_tensors=\"pt\",\n",
        "                    max_length=config.max_prompt_length,\n",
        "                    truncation=True\n",
        "                )\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = model.generate(\n",
        "                        inputs,\n",
        "                        max_new_tokens=300,  # Increased for A100\n",
        "                        do_sample=True,\n",
        "                        temperature=0.7,\n",
        "                        top_p=0.9,\n",
        "                        pad_token_id=tokenizer.pad_token_id,\n",
        "                        eos_token_id=tokenizer.eos_token_id\n",
        "                    )\n",
        "\n",
        "                response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "                response = response[len(tokenizer.decode(inputs[0], skip_special_tokens=True)):].strip()\n",
        "\n",
        "                results.append({\n",
        "                    'example_id': example_idx,\n",
        "                    'query': query,\n",
        "                    'dpo_response': response,  # CHANGED: Updated to dpo_response\n",
        "                    'model_type': 'fine_tuned_plus_dpo_a100',  # CHANGED: Updated model type\n",
        "                    'response_length': len(response),\n",
        "                })\n",
        "\n",
        "                print(f\"ü§ñ DPO Response: {response[:200]}...\")\n",
        "\n",
        "        # Save detailed test results\n",
        "        timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "        results_file = f\"{config.output_dir}/test_results_a100_dpo_{timestamp}.json\"  # CHANGED: Updated filename\n",
        "\n",
        "        with open(results_file, 'w') as f:\n",
        "            json.dump(results, f, indent=2)\n",
        "\n",
        "        # Generate summary statistics\n",
        "        response_lengths = [r['response_length'] for r in results]\n",
        "\n",
        "        print(f\"\\n‚úÖ A100-Optimized DPO Testing completed!\")  # CHANGED: Updated message\n",
        "        print(f\"üìÅ Results saved to: {results_file}\")\n",
        "        print(f\"üìä Tested on {len(results)} examples\")\n",
        "        print(f\"üìè Average response length: {np.mean(response_lengths):.1f} characters\")\n",
        "        print(f\"üìè Response length range: {min(response_lengths)} - {max(response_lengths)}\")\n",
        "\n",
        "        print(\"\\nüîç A100 DPO COMPARISON ANALYSIS:\")  # CHANGED: Updated analysis\n",
        "        print(\"Compare with your original fine-tuned model results for:\")\n",
        "        print(\"  ‚Ä¢ Better preference alignment (chooses better responses)\")\n",
        "        print(\"  ‚Ä¢ More consistent quality across responses\")\n",
        "        print(\"  ‚Ä¢ Improved empathy and professional guidance balance\")\n",
        "        print(\"  ‚Ä¢ Better adherence to therapeutic best practices\")\n",
        "        print(\"  ‚Ä¢ More nuanced understanding of user preferences\")\n",
        "        print(\"  ‚Ä¢ Reduced harmful or inappropriate responses\")\n",
        "\n",
        "        return results\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error during testing: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        return []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ce6697b3b7134221a787446ee8d382a3",
            "9e8903ea451e48fc9ed040bb7e0bdd9a",
            "25a622c2ec35429e9a0fd16dca7b99db",
            "dc3dfb0d53d6493fba97a40cfe216553",
            "00dd104381064d9d91443cd9b0d9bd45",
            "bfa359a137944577a9017137359ab65f",
            "323cd054511d4bdbb6b720bed9c7e572",
            "2fca8a1da12447948be950688e39341e",
            "6681a7d470a140debbedbebdf31b32f2",
            "f9ec0d7b43c5473fa4982bc6f45ff0f6",
            "b5b78afb171447f1a45abeb101e38d96",
            "ccb35dffc8b34e35bf5fb50f37e824ed",
            "b24574fff0794ecc81b977d4b1934e26",
            "c5f4e283df5944ecbb7d929d074b4dfc",
            "149910c4a04c4a7c8df12e77aae1e7b8",
            "739f35b532374f28b466aa3d18439f61",
            "05306d63ea854d31afab0b774a14fd98",
            "ab51969e9823432a942cb3ff3d16c043",
            "a5e799016f2f46b5b68e7335361b1e39",
            "0efbdf1bdd4c433bbf5d7368f7496fcf",
            "fcb2519d372844748c0145486f1249ce",
            "338688ceec8c45f79837692576db4ec2",
            "d125794a6d1b44b3a1d3179cf0272dd8",
            "5e4f7442486a47bbb43459378fb5d26c",
            "857d47fff9314e239a292aee8c021816",
            "eef5974907874453a969bda7bed2e6fe",
            "5f5de981e8464c6abdd40025ea9abed7",
            "124feb173cd640399536eb5a88a2427b",
            "9458aab07aee44b4b74803a7a0862845",
            "ef502fc1ef0943d79e83b1fed708cd94",
            "31e29c3760464a1d96cce8df8071d9f7",
            "939c1ea09658400b80c04506151b3da4",
            "ed8eb8db617a49cbb5e763a2f984d25c",
            "db07582823b24df29181281f69cc6fc3",
            "ca5aab97cf9b40d6b8b771b59d985fe1",
            "9222874312ba4705a1e5bb54953ec90f",
            "00505c0be05b4768ae0ebcc2a3375d89",
            "6a482af85ca14bd2ab71edcecd06bf53",
            "109ea358ae104332b687dde525ab4f8f",
            "66a696e06348401297d4dc57962b14ee",
            "38eeccb6d9134e49a57328393f8bc7d8",
            "d413f194f60d47c0a9c886cd5fb1bfd0",
            "7e61dccfc33f4aa2b9728aaac64d59ba",
            "c01aaf3b4f9d4995885c67605db7b7b4",
            "993c718b9a934cc2a87f056542e3b861",
            "ee97b0b7234946d8a5387b760b9b7edf",
            "1e832e4e473740249f9c51172b41074a",
            "01b9416596b042f199f25b1fd10c2f6d",
            "bd2c435617264ac3b72a9c27d0123c7c",
            "c9377983a569471bba09e62a0ee8882e",
            "316d0a1064d149a99e02b1c9c12a254c",
            "c6f017196b9447be9de4a2cc4cb3ef69",
            "29e7fcdbd0014899b0670a9f7a08241a",
            "083f4f2f0cf441b487fdfa50f429c0f1",
            "96f636694dba4c5492e007141730a124",
            "a3b0e383f8314382b1c7f01053a1c72f",
            "c4ee61c309f84f40b033aff4021b2664",
            "6de95046fc6d4b0cb5051cc07d85cff4",
            "525308e0332d436d871527c2acb39c83",
            "e8863e8a0bf640dcb25d58cd3c98bb9d",
            "ca571cd6722e4beea99ff4f71480a0bd",
            "2e2b873aeeeb4917afaedb9cc82b8338",
            "9897d86ff9cc48659f0c796c1e4bc839",
            "51616c25c2fc48c28e0980bec1e028d1",
            "ef69bca56058457bada228bcab856b20",
            "f7c585717a744efd8a23029c1f573010",
            "afa4fb4aaa554cec961b00d3eee2099a",
            "c62f1e2db99444958c1d0035c5bfc95e",
            "fac39db7dc7f435f94dda886b06cc58e",
            "14f42ab693734cfd98d3181cdb129647",
            "0881bfa22ce5484683a8a581e074216c",
            "d2624489ab0b40e580a0b3d8ca2490e3",
            "6cc98dfe548742b399a867ba7457825f",
            "67e13a97fc9a4b599d2f0bd6d95e71fd",
            "2ab8410ef638409a90bda3736cad064f",
            "dab943da92ac43d58fa1f63cd65cc68a",
            "cd70a65fc9db4627a3666c03ef80479d",
            "8ce0bc368ce6442982a9544f6e2842ec",
            "c2a0c1c560af462db33b2008ec2c2ea1",
            "545c094afe0549a8b5d519906f85d9df",
            "5cbdc73241074cada3d317c1a2b3cc3f",
            "599608ae9e9646239fef16017c0209c4",
            "6de63071bad6446d9ac654609cdcf817",
            "98a3998961864282ab371e5c01b04add",
            "29538528698a4307876e3cd8dc687575",
            "4c0e8f0e6f2c48d4a2c0aaefbff87b19",
            "d2e6c7cf009e462b98c60d9649389dc7",
            "49fbb34b795c442ca35a98b8887b6d44",
            "cc4f1982167f4cd6af77eab15bbd0dd9",
            "dee85efb6e034cd0b44c274f6eeb91b4",
            "669c4c98a8284f6c80261447d717a1b4",
            "30e02ab4e1534214a9787ec686283009",
            "499319956cf3476e8dd6cf074de6595e",
            "dcfb142ed0fe4badb20be0a04fa01222",
            "9f6b321e0ebf4a8db2becd0f79a0c740",
            "7a34c2bf9f394902a007ef2971063f00",
            "ced6d94a39c940c4a3a145f5005ac6d8",
            "4d2f427d910f460db76d3836f2e0b0bf",
            "5c6e9156148d42399d0c9bbed3a21224",
            "9fab7156e3d84314af5ac3de3ffa5363",
            "ba3587f16c0049d589e8f6390f8fcda0",
            "e652bdd140b34379a67ac5e7efd40cc2",
            "5cbd919704064ad5acdbd16d1eac6370",
            "773f1eb5147749da99a55fa7f07589de",
            "aad6759b87484c94acb59ddf907da669",
            "f25537796e6f4095be997e3f1c42c8ad",
            "9508a044d626417e8e2037891653ce8b",
            "1c64dc1fff634d06900e6a104df6ec60",
            "16aa87731a0f493e893680a421c8d552",
            "76ab1ffadace494caf6d3ae84b5f58f1",
            "9b01d038a79b4531ac310d6edc90bacf",
            "9028a47054ca4160866f92f4c82f0cb9",
            "5a3dc0635c2545beb02df7cb9a9d26e5",
            "76a54b96f47f41daa0956b144c42662c",
            "282f1b4e337d4814a6c10620288f0418",
            "51ead26cf6e64548971bdcf8391f16ca",
            "f197ed59eae34ea4be4decf69b76229c",
            "422365b6a9374f1196b7909f3cb7cb51",
            "2e20e79b47d34b5896835f9b4b406256",
            "60d36280185e4bd08ac910a4b868210b",
            "ceb2b753f645475eb1c8fa08a1f8a4ed",
            "849a2c5f3a2d438f94bca331586fc34c",
            "7caaa37182a041498e5f9964366b3d80",
            "1468b89ffa5d4700a99f51cadfef0be0",
            "8a1f41746f7045768fdac29d8b81a5d1",
            "ade7fd1bc88046c9ad33e6c1a8792de9",
            "d467c8c9188c4509b2e53a257d48f800",
            "fad3d0562f544afe92d9109e1e0d5d4e",
            "9eeb059453314db9ae3db8e079b7e32d",
            "cfa99dd0548d4ea6b8dd5ce7607ef2e1",
            "d2d35758370f49fab4fb1dfb33b3b348",
            "724b99b8757a4e2ba731ce813991b5bb"
          ]
        },
        "id": "S3CE9tJYnbxh",
        "outputId": "3f887869-dc42-4d88-ae8d-9eb54c1c2bbf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "======================================================================\n",
            "üéØ LLAMA 3.1 THERAPY MODEL - A100-OPTIMIZED DPO TRAINING\n",
            "======================================================================\n",
            "üöÄ Leveraging A100 power for faster, higher-quality training!\n",
            "‚ö° Expected training time: 1-3 hours\n",
            "üéØ Using Direct Preference Optimization (DPO) for stability!\n",
            "======================================================================\n",
            "üéì Starting A100-Optimized DPO Training...\n",
            "üöÄ Setting up A100-optimized DPO training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mkeera\u001b[0m (\u001b[33mkeera-nanyang-technological-university-singapore\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ wandb login successful\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250629_130416-caj9kgod</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/keera-nanyang-technological-university-singapore/llama-therapy-dpo/runs/caj9kgod' target=\"_blank\">dpo-training-20250629-130416</a></strong> to <a href='https://wandb.ai/keera-nanyang-technological-university-singapore/llama-therapy-dpo' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/keera-nanyang-technological-university-singapore/llama-therapy-dpo' target=\"_blank\">https://wandb.ai/keera-nanyang-technological-university-singapore/llama-therapy-dpo</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/keera-nanyang-technological-university-singapore/llama-therapy-dpo/runs/caj9kgod' target=\"_blank\">https://wandb.ai/keera-nanyang-technological-university-singapore/llama-therapy-dpo/runs/caj9kgod</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ wandb initialized successfully\n",
            "üìö Loading model and dataset...\n",
            "ü¶ô Loading fine-tuned Llama 3.1 therapy model for DPO (A100 optimized)...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce6697b3b7134221a787446ee8d382a3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Fine-tuned model loaded successfully with A100 optimizations!\n",
            "üìä Model device: cuda:0\n",
            "üß† Model dtype: torch.bfloat16\n",
            "üîß Ready for DPO training!\n",
            "üìö Loading PsychoCounsel preference dataset for DPO...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Dataset columns: ['ID', 'prefID', 'question', 'chosen', 'rejected', 'chosen_model', 'rejected_model', 'chosen_empathy_rating', 'chosen_relevance_rating', 'chosen_clarity_rating', 'chosen_safety_rating', 'chosen_exploration_rating', 'chosen_autonomy_rating', 'chosen_staging_rating', 'rejected_empathy_rating', 'rejected_relevance_rating', 'rejected_clarity_rating', 'rejected_safety_rating', 'rejected_exploration_rating', 'rejected_autonomy_rating', 'rejected_staging_rating']\n",
            "üìä Dataset size: 34329\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccb35dffc8b34e35bf5fb50f37e824ed",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/34329 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ Dataset loaded and formatted for DPO: 34329 examples\n",
            "üöÄ Using random subset of 3500 examples for faster training\n",
            "üìù Sample prompt: I've just learned that my father left me out of his IRA, only leaving it to my two younger siblings....\n",
            "üìù Sample chosen: It sounds like you're going through a really difficult time, and it's understandable that you're fee...\n",
            "üìù Sample rejected: I'm sorry that you are going through this difficult time. It is natural to feel betrayed and hurt by...\n",
            "üîÑ Splitting dataset for train/eval...\n",
            "üìä Train dataset: 3150 examples\n",
            "üìä Eval dataset: 350 examples\n",
            "üéØ Setting up DPO configuration...\n",
            "üèãÔ∏è Initializing DPO trainer...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d125794a6d1b44b3a1d3179cf0272dd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting prompt in train dataset:   0%|          | 0/3150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "db07582823b24df29181281f69cc6fc3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template to train dataset:   0%|          | 0/3150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "993c718b9a934cc2a87f056542e3b861",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing train dataset:   0%|          | 0/3150 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3b0e383f8314382b1c7f01053a1c72f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Extracting prompt in eval dataset:   0%|          | 0/350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "afa4fb4aaa554cec961b00d3eee2099a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Applying chat template to eval dataset:   0%|          | 0/350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ce0bc368ce6442982a9544f6e2842ec",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Tokenizing eval dataset:   0%|          | 0/350 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ DPO trainer initialized successfully!\n",
            "üìä Training dataset size: 3150\n",
            "üìä Evaluation dataset size: 350\n",
            "üéØ Batch size: 1\n",
            "üìè Max sequence length: 512\n",
            "üé≤ Beta parameter: 0.1\n",
            "üìà Evaluation every 50 steps\n",
            "üöÄ Starting DPO training...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1182' max='1182' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1182/1182 3:03:58, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Rewards/chosen</th>\n",
              "      <th>Rewards/rejected</th>\n",
              "      <th>Rewards/accuracies</th>\n",
              "      <th>Rewards/margins</th>\n",
              "      <th>Logps/chosen</th>\n",
              "      <th>Logps/rejected</th>\n",
              "      <th>Logits/chosen</th>\n",
              "      <th>Logits/rejected</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.244500</td>\n",
              "      <td>0.148293</td>\n",
              "      <td>3.051175</td>\n",
              "      <td>-2.529736</td>\n",
              "      <td>0.954286</td>\n",
              "      <td>5.580911</td>\n",
              "      <td>-323.193268</td>\n",
              "      <td>-308.365143</td>\n",
              "      <td>0.634078</td>\n",
              "      <td>0.653803</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>100</td>\n",
              "      <td>0.056000</td>\n",
              "      <td>0.114400</td>\n",
              "      <td>3.912790</td>\n",
              "      <td>-2.493588</td>\n",
              "      <td>0.960000</td>\n",
              "      <td>6.406377</td>\n",
              "      <td>-314.577087</td>\n",
              "      <td>-308.003662</td>\n",
              "      <td>0.535900</td>\n",
              "      <td>0.542549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>150</td>\n",
              "      <td>0.031400</td>\n",
              "      <td>0.088100</td>\n",
              "      <td>3.976796</td>\n",
              "      <td>-3.071954</td>\n",
              "      <td>0.971429</td>\n",
              "      <td>7.048750</td>\n",
              "      <td>-313.937042</td>\n",
              "      <td>-313.787354</td>\n",
              "      <td>0.512362</td>\n",
              "      <td>0.500131</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>200</td>\n",
              "      <td>0.009700</td>\n",
              "      <td>0.085035</td>\n",
              "      <td>3.974954</td>\n",
              "      <td>-3.478834</td>\n",
              "      <td>0.968571</td>\n",
              "      <td>7.453788</td>\n",
              "      <td>-313.955475</td>\n",
              "      <td>-317.856110</td>\n",
              "      <td>0.412503</td>\n",
              "      <td>0.387117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>250</td>\n",
              "      <td>0.005200</td>\n",
              "      <td>0.069061</td>\n",
              "      <td>3.999490</td>\n",
              "      <td>-3.643056</td>\n",
              "      <td>0.974286</td>\n",
              "      <td>7.642546</td>\n",
              "      <td>-313.710083</td>\n",
              "      <td>-319.498352</td>\n",
              "      <td>0.275347</td>\n",
              "      <td>0.255954</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>300</td>\n",
              "      <td>0.009500</td>\n",
              "      <td>0.070254</td>\n",
              "      <td>3.541062</td>\n",
              "      <td>-4.409264</td>\n",
              "      <td>0.974286</td>\n",
              "      <td>7.950325</td>\n",
              "      <td>-318.294373</td>\n",
              "      <td>-327.160461</td>\n",
              "      <td>0.183732</td>\n",
              "      <td>0.167881</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>350</td>\n",
              "      <td>0.061400</td>\n",
              "      <td>0.067824</td>\n",
              "      <td>3.554749</td>\n",
              "      <td>-4.512812</td>\n",
              "      <td>0.982857</td>\n",
              "      <td>8.067562</td>\n",
              "      <td>-318.157501</td>\n",
              "      <td>-328.195923</td>\n",
              "      <td>0.134294</td>\n",
              "      <td>0.109103</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>0.062308</td>\n",
              "      <td>3.331196</td>\n",
              "      <td>-4.958302</td>\n",
              "      <td>0.982857</td>\n",
              "      <td>8.289497</td>\n",
              "      <td>-320.393066</td>\n",
              "      <td>-332.650818</td>\n",
              "      <td>-0.024481</td>\n",
              "      <td>-0.057874</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>450</td>\n",
              "      <td>0.005900</td>\n",
              "      <td>0.058349</td>\n",
              "      <td>2.976055</td>\n",
              "      <td>-6.197842</td>\n",
              "      <td>0.982857</td>\n",
              "      <td>9.173897</td>\n",
              "      <td>-323.944458</td>\n",
              "      <td>-345.046265</td>\n",
              "      <td>-0.180841</td>\n",
              "      <td>-0.226976</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.002000</td>\n",
              "      <td>0.061777</td>\n",
              "      <td>2.461832</td>\n",
              "      <td>-7.335789</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>9.797622</td>\n",
              "      <td>-329.086700</td>\n",
              "      <td>-356.425720</td>\n",
              "      <td>-0.331480</td>\n",
              "      <td>-0.381586</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>550</td>\n",
              "      <td>0.007200</td>\n",
              "      <td>0.059545</td>\n",
              "      <td>2.868831</td>\n",
              "      <td>-6.422214</td>\n",
              "      <td>0.982857</td>\n",
              "      <td>9.291045</td>\n",
              "      <td>-325.016693</td>\n",
              "      <td>-347.289917</td>\n",
              "      <td>-0.273337</td>\n",
              "      <td>-0.328960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>600</td>\n",
              "      <td>0.004200</td>\n",
              "      <td>0.056715</td>\n",
              "      <td>2.314764</td>\n",
              "      <td>-7.665277</td>\n",
              "      <td>0.985714</td>\n",
              "      <td>9.980041</td>\n",
              "      <td>-330.557373</td>\n",
              "      <td>-359.720581</td>\n",
              "      <td>-0.338279</td>\n",
              "      <td>-0.396820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>650</td>\n",
              "      <td>0.004300</td>\n",
              "      <td>0.056544</td>\n",
              "      <td>2.795317</td>\n",
              "      <td>-6.896374</td>\n",
              "      <td>0.982857</td>\n",
              "      <td>9.691691</td>\n",
              "      <td>-325.751831</td>\n",
              "      <td>-352.031555</td>\n",
              "      <td>-0.322139</td>\n",
              "      <td>-0.379032</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>700</td>\n",
              "      <td>0.003000</td>\n",
              "      <td>0.059022</td>\n",
              "      <td>2.582771</td>\n",
              "      <td>-6.972593</td>\n",
              "      <td>0.982857</td>\n",
              "      <td>9.555364</td>\n",
              "      <td>-327.877319</td>\n",
              "      <td>-352.793732</td>\n",
              "      <td>-0.368364</td>\n",
              "      <td>-0.423332</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>750</td>\n",
              "      <td>0.005000</td>\n",
              "      <td>0.055543</td>\n",
              "      <td>2.337352</td>\n",
              "      <td>-7.873149</td>\n",
              "      <td>0.980000</td>\n",
              "      <td>10.210502</td>\n",
              "      <td>-330.331512</td>\n",
              "      <td>-361.799255</td>\n",
              "      <td>-0.440100</td>\n",
              "      <td>-0.498301</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.000800</td>\n",
              "      <td>0.052607</td>\n",
              "      <td>2.492487</td>\n",
              "      <td>-7.866630</td>\n",
              "      <td>0.985714</td>\n",
              "      <td>10.359118</td>\n",
              "      <td>-328.780151</td>\n",
              "      <td>-361.734070</td>\n",
              "      <td>-0.450582</td>\n",
              "      <td>-0.516462</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>850</td>\n",
              "      <td>0.001200</td>\n",
              "      <td>0.051934</td>\n",
              "      <td>2.471814</td>\n",
              "      <td>-7.979137</td>\n",
              "      <td>0.985714</td>\n",
              "      <td>10.450953</td>\n",
              "      <td>-328.986877</td>\n",
              "      <td>-362.859161</td>\n",
              "      <td>-0.459416</td>\n",
              "      <td>-0.527982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>900</td>\n",
              "      <td>0.000900</td>\n",
              "      <td>0.053505</td>\n",
              "      <td>2.376857</td>\n",
              "      <td>-8.213672</td>\n",
              "      <td>0.982857</td>\n",
              "      <td>10.590530</td>\n",
              "      <td>-329.936462</td>\n",
              "      <td>-365.204529</td>\n",
              "      <td>-0.486587</td>\n",
              "      <td>-0.556362</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>950</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.053254</td>\n",
              "      <td>2.434043</td>\n",
              "      <td>-8.026922</td>\n",
              "      <td>0.985714</td>\n",
              "      <td>10.460964</td>\n",
              "      <td>-329.364563</td>\n",
              "      <td>-363.337036</td>\n",
              "      <td>-0.484586</td>\n",
              "      <td>-0.554714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.000100</td>\n",
              "      <td>0.052648</td>\n",
              "      <td>2.335060</td>\n",
              "      <td>-8.381781</td>\n",
              "      <td>0.985714</td>\n",
              "      <td>10.716842</td>\n",
              "      <td>-330.354431</td>\n",
              "      <td>-366.885590</td>\n",
              "      <td>-0.510976</td>\n",
              "      <td>-0.582575</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1050</td>\n",
              "      <td>0.000400</td>\n",
              "      <td>0.052940</td>\n",
              "      <td>2.367155</td>\n",
              "      <td>-8.336811</td>\n",
              "      <td>0.985714</td>\n",
              "      <td>10.703968</td>\n",
              "      <td>-330.033478</td>\n",
              "      <td>-366.435944</td>\n",
              "      <td>-0.513500</td>\n",
              "      <td>-0.585393</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1100</td>\n",
              "      <td>0.000700</td>\n",
              "      <td>0.053908</td>\n",
              "      <td>2.338773</td>\n",
              "      <td>-8.416921</td>\n",
              "      <td>0.985714</td>\n",
              "      <td>10.755694</td>\n",
              "      <td>-330.317291</td>\n",
              "      <td>-367.237030</td>\n",
              "      <td>-0.520601</td>\n",
              "      <td>-0.593080</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1150</td>\n",
              "      <td>0.000500</td>\n",
              "      <td>0.053805</td>\n",
              "      <td>2.305216</td>\n",
              "      <td>-8.510265</td>\n",
              "      <td>0.985714</td>\n",
              "      <td>10.815480</td>\n",
              "      <td>-330.652832</td>\n",
              "      <td>-368.170441</td>\n",
              "      <td>-0.527262</td>\n",
              "      <td>-0.599973</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The get_url method is deprecated and will be removed in a future release. Please use `run.url` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ DPO training completed successfully!\n",
            "üíæ Saving final model...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Trainer.tokenizer is now deprecated. You should use Trainer.processing_class instead.\n"
          ]
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>data/dataset_size</td><td>‚ñÅ</td></tr><tr><td>eval/logits/chosen</td><td>‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/logits/rejected</td><td>‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÉ‚ñÇ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/logps/chosen</td><td>‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/logps/rejected</td><td>‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/loss</td><td>‚ñà‚ñÜ‚ñÑ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/rewards/accuracies</td><td>‚ñÅ‚ñÇ‚ñÖ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñà‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/rewards/chosen</td><td>‚ñÑ‚ñà‚ñà‚ñà‚ñà‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÅ‚ñÉ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/rewards/margins</td><td>‚ñÅ‚ñÇ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>eval/rewards/rejected</td><td>‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÑ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>eval/runtime</td><td>‚ñÅ‚ñÇ‚ñÖ‚ñÇ‚ñÉ‚ñÉ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÑ‚ñÜ‚ñÑ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñÜ</td></tr><tr><td>eval/samples_per_second</td><td>‚ñà‚ñá‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ</td></tr><tr><td>eval/steps_per_second</td><td>‚ñà‚ñá‚ñÑ‚ñá‚ñÜ‚ñÖ‚ñÑ‚ñÑ‚ñÖ‚ñÑ‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÉ‚ñÑ‚ñÉ‚ñÖ‚ñÇ‚ñÉ‚ñÑ‚ñÇ‚ñÉ</td></tr><tr><td>model/num_parameters</td><td>‚ñÅ</td></tr><tr><td>model/trainable_parameters</td><td>‚ñÅ</td></tr><tr><td>system/gpu_memory_gb</td><td>‚ñÅ</td></tr><tr><td>train/epoch</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/global_step</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÑ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñá‚ñà‚ñà</td></tr><tr><td>train/grad_norm</td><td>‚ñÅ‚ñÅ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/learning_rate</td><td>‚ñà‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/logits/chosen</td><td>‚ñà‚ñà‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÑ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÉ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/logits/rejected</td><td>‚ñà‚ñá‚ñà‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÑ‚ñÖ‚ñÉ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÉ‚ñÉ‚ñÉ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÇ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/logps/chosen</td><td>‚ñÉ‚ñÉ‚ñÉ‚ñÖ‚ñà‚ñÑ‚ñÇ‚ñÜ‚ñÇ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÜ‚ñà‚ñÜ‚ñÜ‚ñá‚ñÇ‚ñÇ‚ñÑ‚ñÇ‚ñá‚ñÑ‚ñá‚ñÖ‚ñÅ‚ñÉ‚ñÖ‚ñÜ‚ñÑ‚ñÉ‚ñÑ‚ñÅ‚ñÜ‚ñÜ‚ñÇ‚ñÜ‚ñÑ‚ñÖ</td></tr><tr><td>train/logps/rejected</td><td>‚ñá‚ñà‚ñÉ‚ñá‚ñÅ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñÖ‚ñá‚ñá‚ñà‚ñá‚ñá‚ñá‚ñà‚ñÇ‚ñá‚ñÇ‚ñá‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñá</td></tr><tr><td>train/loss</td><td>‚ñÜ‚ñà‚ñÖ‚ñÖ‚ñÉ‚ñÖ‚ñá‚ñÑ‚ñÑ‚ñÇ‚ñÑ‚ñÉ‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÇ‚ñÅ‚ñÑ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ‚ñÅ</td></tr><tr><td>train/rewards/accuracies</td><td>‚ñÖ‚ñÖ‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñÖ‚ñÖ‚ñÖ‚ñÅ‚ñà‚ñÅ‚ñÅ‚ñÅ‚ñÖ‚ñÖ‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà</td></tr><tr><td>train/rewards/chosen</td><td>‚ñÅ‚ñÇ‚ñÇ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñÖ‚ñá‚ñá‚ñÖ‚ñÜ‚ñÜ‚ñà‚ñÜ‚ñÑ‚ñÖ‚ñÖ‚ñá‚ñÖ‚ñÑ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÜ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÖ</td></tr><tr><td>train/rewards/margins</td><td>‚ñÅ‚ñÑ‚ñÑ‚ñÑ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñÜ‚ñá‚ñá‚ñá‚ñá‚ñà‚ñá‚ñà‚ñà‚ñá‚ñá‚ñá‚ñÜ‚ñá</td></tr><tr><td>train/rewards/rejected</td><td>‚ñà‚ñá‚ñÜ‚ñÜ‚ñá‚ñÜ‚ñÜ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñÑ‚ñÉ‚ñÑ‚ñÑ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÉ‚ñÇ‚ñÉ‚ñÅ‚ñÇ‚ñÇ‚ñÅ‚ñÅ‚ñÇ‚ñÇ‚ñÇ‚ñÅ</td></tr><tr><td>training/final_loss</td><td>‚ñÅ</td></tr><tr><td>training/total_steps</td><td>‚ñÅ</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>data/dataset_size</td><td>3500</td></tr><tr><td>eval/logits/chosen</td><td>-0.52726</td></tr><tr><td>eval/logits/rejected</td><td>-0.59997</td></tr><tr><td>eval/logps/chosen</td><td>-330.65283</td></tr><tr><td>eval/logps/rejected</td><td>-368.17044</td></tr><tr><td>eval/loss</td><td>0.05381</td></tr><tr><td>eval/rewards/accuracies</td><td>0.98571</td></tr><tr><td>eval/rewards/chosen</td><td>2.30522</td></tr><tr><td>eval/rewards/margins</td><td>10.81548</td></tr><tr><td>eval/rewards/rejected</td><td>-8.51027</td></tr><tr><td>eval/runtime</td><td>170.5019</td></tr><tr><td>eval/samples_per_second</td><td>2.053</td></tr><tr><td>eval/steps_per_second</td><td>2.053</td></tr><tr><td>model/num_parameters</td><td>4624486400</td></tr><tr><td>model/trainable_parameters</td><td>83886080</td></tr><tr><td>system/gpu_memory_gb</td><td>42.47447</td></tr><tr><td>system/gpu_name</td><td>NVIDIA A100-SXM4-40G...</td></tr><tr><td>total_flos</td><td>0</td></tr><tr><td>train/epoch</td><td>3</td></tr><tr><td>train/global_step</td><td>1182</td></tr><tr><td>train/grad_norm</td><td>0.06255</td></tr><tr><td>train/learning_rate</td><td>0.0</td></tr><tr><td>train/logits/chosen</td><td>-0.52273</td></tr><tr><td>train/logits/rejected</td><td>-0.49443</td></tr><tr><td>train/logps/chosen</td><td>-334.55142</td></tr><tr><td>train/logps/rejected</td><td>-424.74847</td></tr><tr><td>train/loss</td><td>0.0002</td></tr><tr><td>train/rewards/accuracies</td><td>1</td></tr><tr><td>train/rewards/chosen</td><td>2.9042</td></tr><tr><td>train/rewards/margins</td><td>12.61265</td></tr><tr><td>train/rewards/rejected</td><td>-9.70844</td></tr><tr><td>train_loss</td><td>0.0443</td></tr><tr><td>train_runtime</td><td>11044.5357</td></tr><tr><td>train_samples_per_second</td><td>0.856</td></tr><tr><td>train_steps_per_second</td><td>0.107</td></tr><tr><td>training/final_loss</td><td>0.0443</td></tr><tr><td>training/total_steps</td><td>1182</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">dpo-training-20250629-130416</strong> at: <a href='https://wandb.ai/keera-nanyang-technological-university-singapore/llama-therapy-dpo/runs/caj9kgod' target=\"_blank\">https://wandb.ai/keera-nanyang-technological-university-singapore/llama-therapy-dpo/runs/caj9kgod</a><br> View project at: <a href='https://wandb.ai/keera-nanyang-technological-university-singapore/llama-therapy-dpo' target=\"_blank\">https://wandb.ai/keera-nanyang-technological-university-singapore/llama-therapy-dpo</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250629_130416-caj9kgod/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ wandb logging completed\n",
            "üéâ DPO Training completed!\n",
            "üìä Final training loss: 0.0443\n",
            "üìà Total training steps: 1182\n",
            "üíæ Model saved to: /content/drive/MyDrive/llama_31_therapist_outputs/dpo_therapy_model\n",
            "\n",
            "‚è±Ô∏è Total DPO training time: 3:04:50.676793\n",
            "\n",
            "==================================================\n",
            "üß™ TESTING THE DPO-TRAINED MODEL\n",
            "==================================================\n",
            "üß™ Testing A100-Optimized DPO model with NickyNicky/nlp-mental-health-conversations...\n",
            "üìÇ Loading DPO model from: /content/drive/MyDrive/llama_31_therapist_outputs/dpo_therapy_model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cc4f1982167f4cd6af77eab15bbd0dd9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìö Loading NickyNicky/nlp-mental-health-conversations for comparison...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9fab7156e3d84314af5ac3de3ffa5363",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/314 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9b01d038a79b4531ac310d6edc90bacf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "train-00000-of-00001.parquet:   0%|          | 0.00/2.46M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "849a2c5f3a2d438f94bca331586fc34c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Generating train split:   0%|          | 0/3512 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä Testing on 100 examples from NickyNicky dataset\n",
            "\n",
            "üîÑ Processing example 1/100\n",
            "üí¨ Query: Context...\n",
            "‚ùå Error during testing: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n",
            "\n",
            "üéâ A100-Optimized DPO Training & Testing Complete!\n",
            "üìä Training completed in: 3:04:50.676793\n",
            "üß™ Tested on 0 examples\n",
            "üíæ Model saved to: /content/drive/MyDrive/llama_31_therapist_outputs/dpo_therapy_model\n",
            "üìà Check your training metrics at: https://wandb.ai\n",
            "\n",
            "üèÜ Your therapy model is now DPO-aligned and ready to use!\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py:2495: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
            "  warnings.warn(\n",
            "Traceback (most recent call last):\n",
            "  File \"/tmp/ipython-input-8-3302275846.py\", line 89, in test_dpo_model\n",
            "    outputs = model.generate(\n",
            "              ^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/utils/_contextlib.py\", line 116, in decorate_context\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 2623, in generate\n",
            "    result = self._sample(\n",
            "             ^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/generation/utils.py\", line 3604, in _sample\n",
            "    outputs = self(**model_inputs, return_dict=True)\n",
            "              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\", line 943, in wrapper\n",
            "    output = func(self, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 552, in forward\n",
            "    outputs: BaseModelOutputWithPast = self.model(\n",
            "                                       ^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/utils/generic.py\", line 943, in wrapper\n",
            "    output = func(self, *args, **kwargs)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/transformers/models/llama/modeling_llama.py\", line 405, in forward\n",
            "    inputs_embeds = self.embed_tokens(input_ids)\n",
            "                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1739, in _wrapped_call_impl\n",
            "    return self._call_impl(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\", line 1750, in _call_impl\n",
            "    return forward_call(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/modules/sparse.py\", line 190, in forward\n",
            "    return F.embedding(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/nn/functional.py\", line 2551, in embedding\n",
            "    return torch.embedding(weight, input, padding_idx, scale_grad_by_freq, sparse)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument index in method wrapper_CUDA__index_select)\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import login\n",
        "\n",
        "# Log in to Hugging Face\n",
        "login(token=\"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\")\n",
        "\n",
        "print(\"=\" * 70)\n",
        "print(\"üéØ LLAMA 3.1 THERAPY MODEL - A100-OPTIMIZED DPO TRAINING\")  # CHANGED: RLHF -> DPO\n",
        "print(\"=\" * 70)\n",
        "print(\"üöÄ Leveraging A100 power for faster, higher-quality training!\")\n",
        "print(\"‚ö° Expected training time: 1-3 hours\")  # CHANGED: DPO is typically faster than PPO\n",
        "print(\"üéØ Using Direct Preference Optimization (DPO) for stability!\")  # ADDED: DPO advantage\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Start training\n",
        "start_time = datetime.now()\n",
        "stats = run_dpo_training()  # CHANGED: run_rlhf_training() -> run_dpo_training()\n",
        "end_time = datetime.now()\n",
        "\n",
        "training_duration = end_time - start_time\n",
        "print(f\"\\n‚è±Ô∏è Total DPO training time: {training_duration}\")  # CHANGED: Added \"DPO\"\n",
        "\n",
        "# Optional: Test the trained model\n",
        "print(\"\\n\" + \"=\" * 50)\n",
        "print(\"üß™ TESTING THE DPO-TRAINED MODEL\")  # CHANGED: Updated test message\n",
        "print(\"=\" * 50)\n",
        "\n",
        "test_results = test_dpo_model()  # CHANGED: test_rlhf_model() -> test_dpo_model()\n",
        "\n",
        "print(f\"\\nüéâ A100-Optimized DPO Training & Testing Complete!\")  # CHANGED: RLHF -> DPO\n",
        "print(f\"üìä Training completed in: {training_duration}\")\n",
        "print(f\"üß™ Tested on {len(test_results)} examples\")\n",
        "print(f\"üíæ Model saved to: {config.output_dir}\")\n",
        "\n",
        "if config.use_wandb:\n",
        "    print(f\"üìà Check your training metrics at: https://wandb.ai\")\n",
        "\n",
        "print(\"\\nüèÜ Your therapy model is now DPO-aligned and ready to use!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "1fe2b28d42ab47518932e4b098a03b43",
            "6174b802e02c439a841a624758909894",
            "8a3b56844c84482c99306274c3e82d5e",
            "f4db603dab484c28a1fc2b043d2e677e",
            "14631c71f62d47938757a23e3daae806",
            "b8fe329fe61e46d59a0154bb254f9d68",
            "eaaabbb4aa454fd6bd87c1619ce62ad2",
            "3a32107e5721474b841788a708798f87",
            "31e5f0870298494d9f42b714b443b101",
            "66177b9c73a047cdbf1dcddc4877f8d1",
            "2dddb432db454b2ba3322db0acc96fa8"
          ]
        },
        "id": "PDQnJINOffnI",
        "outputId": "2b06606e-655f-4f40-f510-605b340b7e1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üß™ Testing DPO-trained therapy model...\n",
            "============================================================\n",
            "üìÇ Loading DPO model from: /content/drive/MyDrive/llama_31_therapist_outputs/dpo_therapy_model\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1fe2b28d42ab47518932e4b098a03b43",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‚úÖ DPO model loaded successfully!\n",
            "üìä Model device: cuda:0\n",
            "üß† Model dtype: torch.bfloat16\n",
            "\n",
            "üß™ Loading test dataset (NickyNicky/nlp-mental-health-conversations)...\n",
            "‚úÖ Test dataset loaded successfully!\n",
            "üìä Dataset keys: ['train']\n",
            "üìä First split info: Dataset({\n",
            "    features: ['Context', 'Response'],\n",
            "    num_rows: 3512\n",
            "})\n",
            "üìä Dataset columns: ['Context', 'Response']\n",
            "üìä Dataset size: 3512\n",
            "üìä First example type: <class 'dict'>\n",
            "üìä First example keys: ['Context', 'Response']\n",
            "üìä First example sample: {'Context': \"I'm going through some things with my feelings and myself. I barely sleep and I do nothing but think about how I'm worthless and how I shouldn't be here.\\n   I've never tried or contempla...\n",
            "üß™ Generating responses on test dataset...\n",
            "Processing test sample 1/10...\n",
            "üìù Context preview: I keep having these random thoughts that I don't want.  Things like \"you aren't worth anything.\"  I ...\n",
            "ü§ñ Generated response preview: It sounds like you're going through a really tough time right now, and it's completely understandable to feel overwhelmed by those negative thoughts. ...\n",
            "----------------------------------------\n",
            "Processing test sample 2/10...\n",
            "üìù Context preview: My mom made a lot of mistakes a couple years back, and I can't seem to forgive her. I want to say th...\n",
            "ü§ñ Generated response preview: It sounds like you're carrying a heavy burden of feelings towards your mom right now, and it's completely understandable that forgiveness feels challe...\n",
            "----------------------------------------\n",
            "Processing test sample 3/10...\n",
            "üìù Context preview: What should I do when we see each other?...\n",
            "ü§ñ Generated response preview: It sounds like you're feeling uncertain and unsure about what to expect or how to navigate your interactions with this person. It's completely natural...\n",
            "----------------------------------------\n",
            "Processing test sample 4/10...\n",
            "üìù Context preview: I'm always listening to my husband, but it feels like he never listens to me.    How do I get my hus...\n",
            "ü§ñ Generated response preview: It sounds like you're feeling frustrated and unheard in your relationship with your husband. It's completely understandable that this can be really ch...\n",
            "----------------------------------------\n",
            "Processing test sample 5/10...\n",
            "üìù Context preview: I've gone to a couple therapy sessions so far and still everytime I walk in I get nervous and shaky....\n",
            "ü§ñ Generated response preview: It's completely understandable that you're feeling nervous and shaky during your therapy sessions. It takes a lot of courage to open up about personal...\n",
            "----------------------------------------\n",
            "Processing test sample 6/10...\n",
            "üìù Context preview: How do you know you have the right therapist for you?\n",
            " How would I know how to \"train\" my therapist ...\n",
            "ü§ñ Generated response preview: Finding the right therapist can indeed feel like an important and sometimes daunting process, but it's completely normal to want to ensure that you're...\n",
            "----------------------------------------\n",
            "Processing test sample 7/10...\n",
            "üìù Context preview: I am in my early 20s and I still live with my parents because I can't afford to live alone.\n",
            "\n",
            "My mo...\n",
            "ü§ñ Generated response preview: It sounds like you're feeling really frustrated and overwhelmed by the situation at home with your mother. It's completely understandable to want more...\n",
            "----------------------------------------\n",
            "Processing test sample 8/10...\n",
            "üìù Context preview: I think i may suffer from depression, and it is affecting my life and sleep. I am on my parent's ins...\n",
            "ü§ñ Generated response preview: It sounds like you're going through a really tough time right now, and it takes a lot of courage to acknowledge your feelings and seek support. It can...\n",
            "----------------------------------------\n",
            "Processing test sample 9/10...\n",
            "üìù Context preview: I use to be so happy. No matter what, I always was happy. I got into a relationship with this guy. I...\n",
            "ü§ñ Generated response preview: It sounds like you're going through an incredibly difficult time right now, and it's completely understandable that you're feeling torn between your f...\n",
            "----------------------------------------\n",
            "Processing test sample 10/10...\n",
            "üìù Context preview: I know that I need to get past my feelings for this person I fell in love with, but t's so difficult...\n",
            "ü§ñ Generated response preview: It sounds like you're going through an incredibly challenging and emotional process right now, and it's completely understandable that you're feeling ...\n",
            "----------------------------------------\n",
            "\n",
            "‚úÖ DPO test responses saved to: /content/drive/MyDrive/llama_31_therapist_outputs/dpo_therapy_model/test_responses_dpo_20250629_163040.json\n",
            "üìä Generated 10 test responses\n",
            "\n",
            "üéØ SAMPLE RESPONSES:\n",
            "============================================================\n",
            "\n",
            "üìù Sample 1:\n",
            "‚ùì Context: I keep having these random thoughts that I don't want.  Things like \"you aren't worth anything.\"  I ...\n",
            "ü§ñ Generated: It sounds like you're going through a really tough time right now, and it's completely understandable to feel overwhelmed by those negative thoughts. It takes a lot of courage to acknowledge them and ...\n",
            "----------------------------------------\n",
            "\n",
            "üìù Sample 2:\n",
            "‚ùì Context: My mom made a lot of mistakes a couple years back, and I can't seem to forgive her. I want to say th...\n",
            "ü§ñ Generated: It sounds like you're carrying a heavy burden of feelings towards your mom right now, and it's completely understandable that forgiveness feels challenging for you. It's important to acknowledge the p...\n",
            "----------------------------------------\n",
            "\n",
            "üìù Sample 3:\n",
            "‚ùì Context: What should I do when we see each other?...\n",
            "ü§ñ Generated: It sounds like you're feeling uncertain and unsure about what to expect or how to navigate your interactions with this person. It's completely natural to feel that way, especially if there have been p...\n",
            "----------------------------------------\n",
            "üßπ GPU memory cleared\n",
            "\n",
            "üéâ DPO MODEL TESTING COMPLETED!\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# üß™ DPO MODEL TESTING - Fixed Version\n",
        "import json\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "from datasets import load_dataset\n",
        "\n",
        "print(\"üß™ Testing DPO-trained therapy model...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Load the saved DPO model\n",
        "dpo_model_path = \"/content/drive/MyDrive/llama_31_therapist_outputs/dpo_therapy_model\"\n",
        "\n",
        "print(f\"üìÇ Loading DPO model from: {dpo_model_path}\")\n",
        "\n",
        "try:\n",
        "    # Load tokenizer and model with proper device handling\n",
        "    tokenizer = AutoTokenizer.from_pretrained(dpo_model_path)\n",
        "    model = AutoModelForCausalLM.from_pretrained(\n",
        "        dpo_model_path,\n",
        "        torch_dtype=torch.bfloat16,\n",
        "        device_map=\"auto\",\n",
        "        trust_remote_code=True\n",
        "    )\n",
        "\n",
        "    print(f\"‚úÖ DPO model loaded successfully!\")\n",
        "    print(f\"üìä Model device: {model.device}\")\n",
        "    print(f\"üß† Model dtype: {model.dtype}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error loading DPO model: {e}\")\n",
        "    raise\n",
        "\n",
        "# Load test dataset (same as fine-tuning)\n",
        "print(\"\\nüß™ Loading test dataset (NickyNicky/nlp-mental-health-conversations)...\")\n",
        "\n",
        "try:\n",
        "    test_dataset = load_dataset(\"NickyNicky/nlp-mental-health-conversations\")\n",
        "    print(\"‚úÖ Test dataset loaded successfully!\")\n",
        "\n",
        "    # Debug: Print dataset structure\n",
        "    print(f\"üìä Dataset keys: {list(test_dataset.keys())}\")\n",
        "    print(f\"üìä First split info: {test_dataset[list(test_dataset.keys())[0]]}\")\n",
        "\n",
        "    # Get the first split (usually 'train')\n",
        "    first_split = list(test_dataset.keys())[0]\n",
        "    dataset_split = test_dataset[first_split]\n",
        "\n",
        "    print(f\"üìä Dataset columns: {dataset_split.column_names}\")\n",
        "    print(f\"üìä Dataset size: {len(dataset_split)}\")\n",
        "\n",
        "    # Show first example structure\n",
        "    if len(dataset_split) > 0:\n",
        "        first_example = dataset_split[0]\n",
        "        print(f\"üìä First example type: {type(first_example)}\")\n",
        "        print(f\"üìä First example keys: {list(first_example.keys()) if isinstance(first_example, dict) else 'Not a dict'}\")\n",
        "        print(f\"üìä First example sample: {str(first_example)[:200]}...\")\n",
        "\n",
        "    use_real_dataset = True\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ö†Ô∏è Error loading test dataset: {e}\")\n",
        "    print(\"üîÑ Using fallback test queries...\")\n",
        "    use_real_dataset = False\n",
        "\n",
        "# Prepare test samples\n",
        "if use_real_dataset:\n",
        "    # Sample 10 random examples for testing\n",
        "    test_samples = dataset_split.shuffle(seed=999).select(range(min(10, len(dataset_split))))\n",
        "\n",
        "    def extract_context_response(example):\n",
        "        \"\"\"Extract context and response from dataset example\"\"\"\n",
        "        # Common field names to check\n",
        "        context_fields = ['Context', 'context', 'input', 'question', 'user', 'text']\n",
        "        response_fields = ['Response', 'response', 'output', 'answer', 'assistant', 'target']\n",
        "\n",
        "        context = \"\"\n",
        "        response = \"\"\n",
        "\n",
        "        # Find context field\n",
        "        for field in context_fields:\n",
        "            if field in example and example[field]:\n",
        "                context = str(example[field]).strip()\n",
        "                break\n",
        "\n",
        "        # Find response field\n",
        "        for field in response_fields:\n",
        "            if field in example and example[field]:\n",
        "                response = str(example[field]).strip()\n",
        "                break\n",
        "\n",
        "        return context, response\n",
        "else:\n",
        "    # Create fallback dataset\n",
        "    fallback_queries = [\n",
        "        \"I've been feeling really anxious lately and can't seem to calm down. What should I do?\",\n",
        "        \"I'm having trouble sleeping due to stress and my mind keeps racing at night.\",\n",
        "        \"I feel like I'm not making progress in therapy and I'm getting discouraged.\",\n",
        "        \"I'm struggling with depression and feel hopeless about my future.\",\n",
        "        \"How can I cope with panic attacks? They're happening more frequently.\",\n",
        "        \"I'm having relationship problems and don't know how to communicate better.\",\n",
        "        \"I feel like I'm not good enough and constantly compare myself to others.\",\n",
        "        \"I'm dealing with grief after losing someone close to me recently.\",\n",
        "        \"I'm having trouble managing my anger and it's affecting my relationships.\",\n",
        "        \"I feel lonely and isolated from others, even when I'm around people.\"\n",
        "    ]\n",
        "    test_samples = [{\"context\": query, \"response\": \"\"} for query in fallback_queries]\n",
        "\n",
        "    def extract_context_response(example):\n",
        "        return example.get(\"context\", \"\"), example.get(\"response\", \"\")\n",
        "\n",
        "print(\"üß™ Generating responses on test dataset...\")\n",
        "\n",
        "responses = []\n",
        "\n",
        "for i, example in enumerate(test_samples):\n",
        "    if use_real_dataset:\n",
        "        context, expected_response = extract_context_response(example)\n",
        "    else:\n",
        "        context, expected_response = extract_context_response(example)\n",
        "\n",
        "    if not context:\n",
        "        print(f\"‚ö†Ô∏è Skipping sample {i+1}: No valid context found\")\n",
        "        continue\n",
        "\n",
        "    print(f\"Processing test sample {i+1}/{len(test_samples)}...\")\n",
        "    print(f\"üìù Context preview: {context[:100]}...\")\n",
        "\n",
        "    # Format prompt for Llama 3.1 Instruct (same as fine-tuning)\n",
        "    formatted_prompt = f\"<|begin_of_text|><|start_header_id|>system<|end_header_id|>\\n\\nYou are a helpful, empathetic mental health assistant.<|eot_id|><|start_header_id|>user<|end_header_id|>\\n\\n{context}<|eot_id|><|start_header_id|>assistant<|end_header_id|>\\n\\n\"\n",
        "\n",
        "    # Tokenize and move to correct device\n",
        "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\")\n",
        "    inputs = {k: v.to(model.device) for k, v in inputs.items()}\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=300,  # Reasonable length for therapy responses\n",
        "            temperature=0.7,\n",
        "            do_sample=True,\n",
        "            top_p=0.9,\n",
        "            repetition_penalty=1.1,\n",
        "            pad_token_id=tokenizer.eos_token_id,\n",
        "            eos_token_id=tokenizer.eos_token_id,\n",
        "        )\n",
        "\n",
        "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Extract only the assistant's response (more robust extraction)\n",
        "    if \"<|start_header_id|>assistant<|end_header_id|>\" in full_response:\n",
        "        assistant_response = full_response.split(\"<|start_header_id|>assistant<|end_header_id|>\")[-1].strip()\n",
        "        # Remove any remaining special tokens or formatting\n",
        "        assistant_response = assistant_response.replace(\"<|eot_id|>\", \"\").strip()\n",
        "    else:\n",
        "        # Fallback: try to extract response after the formatted prompt\n",
        "        prompt_end = formatted_prompt.rstrip()\n",
        "        if prompt_end in full_response:\n",
        "            assistant_response = full_response[len(prompt_end):].strip()\n",
        "        else:\n",
        "            # Last resort: take everything after the original input\n",
        "            input_text = tokenizer.decode(inputs['input_ids'][0], skip_special_tokens=True)\n",
        "            if input_text in full_response:\n",
        "                assistant_response = full_response[len(input_text):].strip()\n",
        "            else:\n",
        "                assistant_response = full_response\n",
        "\n",
        "    responses.append({\n",
        "        'context': context,\n",
        "        'expected_response': expected_response,\n",
        "        'generated_response': assistant_response,\n",
        "        'model': 'Llama-3.1-8B-DPO-Therapist',\n",
        "        'sample_id': i+1\n",
        "    })\n",
        "\n",
        "    # Print a preview of the response\n",
        "    print(f\"ü§ñ Generated response preview: {assistant_response[:150]}...\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Save test responses\n",
        "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
        "output_file = f\"{dpo_model_path}/test_responses_dpo_{timestamp}.json\"\n",
        "\n",
        "with open(output_file, 'w', encoding='utf-8') as f:\n",
        "    json.dump(responses, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"\\n‚úÖ DPO test responses saved to: {output_file}\")\n",
        "print(f\"üìä Generated {len(responses)} test responses\")\n",
        "\n",
        "# Print some example responses\n",
        "print(\"\\nüéØ SAMPLE RESPONSES:\")\n",
        "print(\"=\" * 60)\n",
        "for i, resp in enumerate(responses[:3]):  # Show first 3 responses\n",
        "    print(f\"\\nüìù Sample {i+1}:\")\n",
        "    print(f\"‚ùì Context: {resp['context'][:100]}...\")\n",
        "    print(f\"ü§ñ Generated: {resp['generated_response'][:200]}...\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "# Clear memory\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"üßπ GPU memory cleared\")\n",
        "\n",
        "print(\"\\nüéâ DPO MODEL TESTING COMPLETED!\")\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNtMgce6iHQV",
        "outputId": "9c7b0618-296a-4451-bd26-31ed7659fbb7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä LOADING DPO TEST RESULTS\n",
            "============================================================\n",
            "üìÅ Loading results from: test_responses_dpo_20250629_163040.json\n",
            "üìä Found 10 test responses\n",
            "\n",
            "================================================================================\n",
            "üß™ DPO MODEL TEST RESULTS\n",
            "================================================================================\n",
            "\n",
            "=== Test Sample 1 ===\n",
            "üí¨ Context: I keep having these random thoughts that I don't want.  Things like \"you aren't worth anything.\"  I know they're my own thoughts but it feels like someone else is saying it.\r\n",
            "\r\n",
            "What is wrong with me, and how can I stop having these thoughts?\n",
            "\n",
            "üìù Expected: Talking to a licensed profession who can discuss this in greater depth can be best.¬†As a general information, in short, I can say that our thoughts are greatly influenced¬†by our early life experiences. Our thoughts are processed through schemes, these are mental images or templates by which we make meaning of the world around us. ¬†While our upbringing has a great influence on the way we see and interact with the world around us as adults, However, we are not condemned to abide by them for life, in psychotherapy, you learn to change negative¬†schemas with positive ones. Yeah, if you had less than optimal childhood you would have some sort of negative schemas that unconsciously lead to self-sabotage your efforts for success and happiness. The research in the field of interpersonal neurobiology suggests that without conscious awareness and reflective practices we tend to interact with the world by repeating old habits of mind. On the other hand, in psychotherapy you can learn helpful¬†strategies to increase your conscious abilities to stay in control of your mind in the present moment and reduce intrusions of negative mind habits.¬†Yoga, meditation, and tai¬†chi are also found to increase self-awareness and lessen the intrusions of negative self-judgment on one's¬†psyche.\n",
            "\n",
            "ü§ñ DPO Generated: It sounds like you're going through a really tough time right now, and it's completely understandable to feel overwhelmed by those negative thoughts. It takes a lot of courage to acknowledge them and seek support.\n",
            "\n",
            "Firstly, it's important to remember that having unwanted thoughts doesn't mean there's something inherently wrong with you. Thoughts are just thoughts - they come and go, and they don't define your worth as a person. \n",
            "\n",
            "When we have intrusive or distressing thoughts, it can be helpful to explore their origins. Try asking yourself what might trigger these thoughts. Is there a particular situation or feeling associated with them? Understanding the context behind these thoughts may provide some insight into why they occur.\n",
            "\n",
            "Now, let's focus on how to manage them:\n",
            "\n",
            "1. **Challenge the thoughts:** When you notice one of these thoughts arise, take a moment to question its validity. Ask yourself if there's evidence supporting this thought or if it's just an opinion. Are there other, more positive things you can say about yourself?\n",
            "\n",
            "2. **Replace with affirmations:** Whenever you catch yourself thinking negatively, consciously counteract it with positive statements. For example, if you think \"you aren't worth anything,\" try replacing it with \"I am deserving of love and respect.\"\n",
            "\n",
            "3. **Practice self-compassion:** Treat yourself with kindness and understanding when these thoughts appear. Remind yourself that it's okay to have difficult moments and that everyone has flaws. Be patient with yourself during this process.\n",
            "\n",
            "4. **\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Test Sample 2 ===\n",
            "üí¨ Context: My mom made a lot of mistakes a couple years back, and I can't seem to forgive her. I want to say that it's okay, but I can't. I feel like even if I did forgive her, I wouldn't be able to say it to her face.\n",
            "\n",
            "üìù Expected: Hi Cleveland, I think I get what you're feeling. You're scared that if you forgive your mom, that would mean it wasn't so bad, or she'll think it's okay to do it again, or she won't realize how hurt you are.¬†I invite you to look at forgiveness in a different way. Forgiveness doesn't have to mean what she did was okay. Not at all. Forgiveness can mean \"I accept what she did, and I don't want to live in her worst moments constantly. I want to put it down and move past it because I want her in my life, because fear and resentment interfere with my relationship with her, and mostly because I'm tired of carrying them (fear and resentment) around constantly.\"You can forgive your mom for yourself, not for her.¬†¬†If there is evidence that your mom wants to respect you moving forward, then it might be worth it to risk putting down the resentment and the grudge that you think you need to protect yourself.¬†¬†Your ability to draw boundaries with her in the present is your biggest protector; let her know in the present what hurts you, and notice her responses.You don't have to say it to her face. Saying it to yourself is more important. Again, forgiving your mom helps you...it reduces your own burden of fear and resentment, leaving space for better things.\n",
            "\n",
            "ü§ñ DPO Generated: It sounds like you're carrying a heavy burden of feelings towards your mom right now, and it's completely understandable that forgiveness feels challenging for you. It's important to acknowledge the pain and hurt that you've experienced, as these emotions are valid and real.\n",
            "\n",
            "Firstly, let's explore what it means for you to forgive in this context. Forgiveness doesn't necessarily mean forgetting or excusing your mom's actions; rather, it's about finding a way to release the negative emotions associated with those experiences. You might find it helpful to reflect on why forgiving feels so difficult for you - is there a specific aspect of what happened that resonates deeply? Understanding the root cause of your resistance to forgiveness can help us navigate this process together.\n",
            "\n",
            "It's also worth considering whether you need to share your forgiveness with your mom at all. Sometimes, we hold onto the expectation that we must express our forgiveness to someone directly, but it's essential to remember that forgiveness is an internal process. You can choose to work through your feelings privately, allowing yourself the time and space to heal without feeling pressured to confront your mom immediately.\n",
            "\n",
            "In our sessions, we could explore different ways to approach forgiveness, such as writing a letter (even if you don't intend to send it), practicing self-compassion, or engaging in activities that promote healing and growth. We'll take it at your pace and ensure that you feel supported throughout this journey. What are your thoughts on where to begin?\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Test Sample 3 ===\n",
            "üí¨ Context: What should I do when we see each other?\n",
            "\n",
            "üìù Expected: I am so sorry that this happened. ¬†Nobody deserves to be outed without their permission. ¬†I would encourage you to get in touch with someone who is supportive and accepting and plan to touch base with them after you see your wife's sister. ¬†You can also plan to take some time for self care after you see her. ¬†For example, if you enjoy bike rides, plan on taking a bike ride afterward. ¬†Plan to do something that feels nurturing and caring. ¬†Best of luck!\n",
            "\n",
            "ü§ñ DPO Generated: It sounds like you're feeling uncertain and unsure about what to expect or how to navigate your interactions with this person. It's completely natural to feel that way, especially if there have been past difficulties in your relationship.\n",
            "\n",
            "Let's explore this further: What specific concerns or emotions come up for you when you think about seeing them? Are you worried about conflict, or perhaps feeling anxious about the potential for more hurtful interactions?\n",
            "\n",
            "If it's safe and healthy to do so, setting clear boundaries can be an effective way to manage these feelings. This could mean establishing some guidelines around communication, such as agreeing on topics that are off-limits or finding ways to de-escalate any tense conversations.\n",
            "\n",
            "Additionally, focusing on self-care before and during your interactions might help you approach the situation with more emotional resilience. This could involve practicing relaxation techniques, seeking support from trusted friends or loved ones, or engaging in activities that bring you joy and comfort.\n",
            "\n",
            "Remember, you deserve to feel respected and supported in all of your relationships. If these interactions continue to cause significant distress, it may also be worth considering whether it‚Äôs necessary to reevaluate the nature of the relationship altogether. \n",
            "\n",
            "How do you feel about trying out some of these strategies? Is there anything else you'd like to discuss first?\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Test Sample 4 ===\n",
            "üí¨ Context: I'm always listening to my husband, but it feels like he never listens to me.    How do I get my husband to listen to me instead of me listening to him all the time?\n",
            "\n",
            "üìù Expected: It's hard when you feel as if you're the only one that's taking the time to listen to your spouse. But, I would look at this as an opportunity to see if you can become aware of what exactly is happening between you, when you try and talk with your husband.¬†Sometimes, it can be in the way dialogue is approached. I would suggest paying attention to the way you begin dialogue with your husband. See if blame and criticism are present. When blame and criticism are included, bids for connection, can quickly go off track. This can sometimes start off with something like: \"why don't you...\" \"you aren't...\" \"you don't...\" Partners can quickly go into defensive mode if they feel they are being attacked and sometimes starting off like this can feel like an attack. ¬†Also, become aware of the time of day or evening when you approach your husband. Sometimes, this can make a big difference for couples as far as when they can truly be present for one another. ¬†If you find this pattern continues, you might consider seeking professional help through couples therapy. A trained couples therapist can help you both understand more about what's happening between you.\n",
            "\n",
            "ü§ñ DPO Generated: It sounds like you're feeling frustrated and unheard in your relationship with your husband. It's completely understandable that this can be really challenging and leave you feeling disheartened.\n",
            "\n",
            "Firstly, it's important to acknowledge how you're feeling and validate those emotions. It takes courage to express them, even if they might feel difficult or uncomfortable. \n",
            "\n",
            "When we notice a pattern where one person is consistently doing more listening than speaking, it can create an imbalance in the dynamic of the relationship. It might be helpful for both of you to explore why this pattern has developed and what each of you needs from the other.\n",
            "\n",
            "To encourage more reciprocal communication, you could try some small steps:\n",
            "\n",
            "1. **Choose a calm moment**: Find a quiet time when both of you have the opportunity to talk without distractions.\n",
            "2. **Use \"I\" statements**: Instead of starting sentences with \"you never,\" try expressing your thoughts using \"I\" statements. For example, say something like, \"I feel unheard when...\" This helps shift the focus away from blame and encourages understanding.\n",
            "3. **Active listening**: When your husband shares, make sure to actively listen by maintaining eye contact, nodding to show you understand, and summarizing his words back to ensure you've got it right. This demonstrates respect for his perspective and may encourage reciprocity.\n",
            "4. **Set aside dedicated conversation times**: Establish regular moments within your day where you intentionally set aside dedicated time to speak openly and honestly with each other. It could be as\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Test Sample 5 ===\n",
            "üí¨ Context: I've gone to a couple therapy sessions so far and still everytime I walk in I get nervous and shaky.  Is this normal? Should I still be feeling like this?\n",
            "\n",
            "üìù Expected: of ¬†I would love to know a little bit more about what's going on in your life but I will attempt an answer.Yes, you could still be shaky and nervous going to therapy. This therapy thing your doing is sometimes scary.¬†First, because your opening up things that you might have never wanted to.¬†Second, your still building a relationship with this therapist person. You may never get over that. The therapist really can't be your \"friend\". They are there to push the buttons that you might not want pushed and help you heal. ¬†That in itself is scary and can make you anxious.¬†Third, you really never know where this therapy thing will go. Yes, there are goals. But sometimes side roads need to be taken and sometimes that is scary.Know this you are in the right place. You are taking steps to change.\n",
            "\n",
            "ü§ñ DPO Generated: It's completely understandable that you're feeling nervous and shaky during your therapy sessions. It takes a lot of courage to open up about personal thoughts and feelings, especially with someone new. \n",
            "\n",
            "Firstly, it's important to acknowledge that these physical sensations are valid responses to the vulnerability you're experiencing. It's natural to feel anxious or apprehensive when stepping into an unfamiliar environment and discussing sensitive topics.\n",
            "\n",
            "While it might seem uncomfortable at times, it's actually a positive sign that you're actively engaging with your emotions and taking steps towards addressing them. Remember, therapy is a safe space where you can express yourself without judgment, so try not to be too hard on yourself for feeling this way.\n",
            "\n",
            "Here are some suggestions that might help:\n",
            "\n",
            "1. **Take deep breaths**: When you notice those physical sensations rising, take slow, deep breaths in through your nose and out through your mouth. This simple technique can help calm both your body and mind.\n",
            "\n",
            "2. **Communicate openly with your therapist**: Letting them know how you're feeling can actually strengthen your relationship. You can say something like, \"I'm feeling really nervous right now. Can we talk about what that feels like for me?\" They'll likely appreciate your honesty and will work with you to create a more comfortable space.\n",
            "\n",
            "3. **Remind yourself of your goals**: Reflect on why you started attending therapy in the first place. What do you hope to achieve? Keeping these goals in mind can provide a sense of purpose and motivation,\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Test Sample 6 ===\n",
            "üí¨ Context: How do you know you have the right therapist for you?\n",
            " How would I know how to \"train\" my therapist to be able to give me what I need from treatment?\n",
            "\n",
            "üìù Expected: Counselors do not expect to gain your trust during the first session. Trust is earned and gained through the therapeutic process. You may know you have the right therapist if you feel a lack of judgement or even unconditional positive regard for the choices you make in therapy. Good counselors will keep you accountable for your actions without making you feel ashamed of the choice you made.Counselors already have the training to give you what you need in treatment, and if they don't they are ethically obligated to refer you to a provider that does. That being said, the first few visits with your counselor will be goal oriented- creating realistic and obtainable goals that will allow you and your therapist to see positive change when it is made.\n",
            "\n",
            "ü§ñ DPO Generated: Finding the right therapist can indeed feel like an important and sometimes daunting process, but it's completely normal to want to ensure that you're getting the support you deserve. It‚Äôs wonderful that you're taking the time to reflect on what you need from your therapy.\n",
            "\n",
            "Here are some suggestions that might help you gauge whether a therapist is a good fit for you:\n",
            "\n",
            "1. **Initial impressions**: Pay attention to how you feel during your first few sessions. Do you feel heard, understood, and supported? Are there any red flags or discomforts that stand out to you?\n",
            "\n",
            "2. **Open communication**: Don't hesitate to express your needs and expectations openly with your therapist. Let them know about specific goals you hope to achieve in therapy, any concerns you may have, or if certain topics make you uncomfortable. This will help create a collaborative space where both of you can work together effectively.\n",
            "\n",
            "3. **Therapist‚Äôs approach**: Reflect on their therapeutic style. Do they listen attentively? Are they empathetic? Do they seem knowledgeable about the issues you're facing? You might also consider asking questions about their approach, such as what modalities they use (e.g., cognitive-behavioral, psychodynamic) or how often they schedule check-ins between sessions.\n",
            "\n",
            "4. **Progress and feedback**: Notice if you're making progress over time. If not, discuss this with your therapist. They should be open to hearing your thoughts and adjusting their approach accordingly. Feeling comfortable providing feedback is crucial because it\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Test Sample 7 ===\n",
            "üí¨ Context: I am in my early 20s and I still live with my parents because I can't afford to live alone.\r\n",
            "\r\n",
            "My mother says that if I live under her roof I have to follow her rules. She is trying to control my life. What should I do?\n",
            "\n",
            "üìù Expected: Unfortunately you seem to have yourself in a double bind. By living with your mom she is not going to stop her attempts at what you perceive as \"controlling\". There is no use in trying to debate or get her to \"see your point\". As long as your there and you personalize her attempts at control, then you will find yourself frustrated and resentful. Try to find an extra job or a roommate so that you can do the natural process of moving on out.www.lifecounselingorlando.com\n",
            "\n",
            "ü§ñ DPO Generated: It sounds like you're feeling really frustrated and overwhelmed by the situation at home with your mother. It's completely understandable to want more independence and autonomy as you navigate this stage of your life.\n",
            "\n",
            "Firstly, it's important to acknowledge that it takes a lot of courage to express these feelings and seek guidance on how to handle them. Here are some suggestions that might be helpful for you:\n",
            "\n",
            "1. **Communication**: Try having an open and honest conversation with your mother about how you feel. Expressing your desire for more independence and space while also acknowledging her concerns and boundaries can create a healthier dynamic between both of you. Approach this conversation calmly and respectfully.\n",
            "\n",
            "2. **Setting Boundaries**: Clearly communicate what you're comfortable with regarding rules and expectations. You don't have to accept all of her requests or compromises if they make you uncomfortable. Setting clear boundaries can help establish mutual respect and understanding within your living arrangement.\n",
            "\n",
            "3. **Exploring Alternatives**: If talking to your mother doesn't lead to significant changes, consider exploring other options for making your financial situation work better. This could involve finding ways to increase your income (part-time job, freelance work, etc.), researching affordable housing options, or seeking support from friends/family who might be able to provide temporary assistance until you find something more sustainable.\n",
            "\n",
            "4. **Self-Reflection and Planning**: Take some time to reflect on your own goals, values, and priorities. What kind of lifestyle do you envision for yourself? Are there any skills or areas\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Test Sample 8 ===\n",
            "üí¨ Context: I think i may suffer from depression, and it is affecting my life and sleep. I am on my parent's insurance, and they won't let me see a therapist because they don't believe in it.\n",
            "\n",
            "üìù Expected: The answer here really depends upon your age and something called the \"age of consent\" in the state where you live. In Pennsylvania, anyone over the age of 14 can provide consent for their own treatment. As for billing purposes, try talking to some local agencies. If you are under 18, you may be able to have Medicaid out of medical necessity so that you can have treatment. If you are over 18, there may be some discounted rates at some agencies because of the situation you're in. Maybe your primary care physician will be able to refer you to some local agencies.If you are in school, you may be able to talk with a guidance counselor or someone at the school. This would not require using your insurance.\n",
            "\n",
            "ü§ñ DPO Generated: It sounds like you're going through a really tough time right now, and it takes a lot of courage to acknowledge your feelings and seek support. It can be incredibly frustrating when we feel our needs aren't being met, especially when it comes to something as important as our mental health.\n",
            "\n",
            "Firstly, know that it's completely valid for you to feel concerned about the impact depression has on your daily life and sleep. It's common for depression to interfere with both physical and emotional well-being, so it's great that you're recognizing this connection.\n",
            "\n",
            "Given the situation with your parents' reluctance to consider therapy, it might feel overwhelming and isolating. However, there are still steps you can take:\n",
            "\n",
            "1. **Self-reflection**: Take some time to explore how these feelings affect you personally. Understanding what symptoms you experience most frequently (e.g., fatigue, low mood, difficulty concentrating) and how often they occur can help you articulate your concerns better.\n",
            "2. **Support networks**: Reach out to trusted friends or family members who might provide an understanding ear. Sometimes just talking about our thoughts and emotions can offer relief and perspective.\n",
            "3. **Online resources**: Look into online communities, forums, or websites dedicated to mental health. Connecting with others who have similar experiences can provide a sense of belonging and valuable insights.\n",
            "4. **Journaling**: Consider keeping a journal where you write down your thoughts, feelings, and any patterns you notice. This can serve as a way to process emotions privately and potentially identify\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Test Sample 9 ===\n",
            "üí¨ Context: I use to be so happy. No matter what, I always was happy. I got into a relationship with this guy. I love him so much. We‚Äôre both teenagers. The week after his birthday, my mom made me stop talking to him. It broke me. He came to my house and talked to her, and she let us date again but not see each other. He comes up to my school every day and it tears me apart that I have to lie to her.\n",
            "\n",
            "üìù Expected: Hi Los Angeles, I can tell you have a moral backbone because it's hurting you to lie to your mom. I always say that a little bit of guilt is healthy because it teaches us who we want to be. Listen to that voice. You don't have to lie to your mom to get what you want.Now, you don't say how old you are, so part of my answer is going to be a bit vague. There's a big difference between being thirteen and your mom telling you what to do and being nineteen and your mom telling you what to do. The thing is that moms and dads start out making all your decisions for you when you're small, and they're supposed to, very gradually, give that control over to you. Different parents do this at different speeds, but in general you have to earn that freedom and trust...it's not just gonna be handed over to you.¬†You might not like this part...your parent has the right to make the rules. My guess is there's a reason why mom is holding you back. Even if it doesn't make sense to you, breaking her rules isn't going to get you what you want...which is freedom, right? I guarantee you that mom wants you to eventually earn freedom...but she's not supposed to give it to you until you're ready because her first job is to keep you safe.¬†I like that your mom has limits for you. Too many parents are sort of looking the other way, busy with their own thing. Whether you know it or not, you need protection like all kids do (appropriate for your age, of course).It sounds like what you want to say to your mom is \"I want to make my own decisions about who I spend time with\". That's a normal wish, and I encourage you to say that to her. Depending on your age and whether you've earned it, she might listen.¬†So, you're sending her that message that you want to send, but you're doing it in a sneaky way, and that's not going to go well when she finds out. It's called \"passive aggressive\" when you say something with a sneaky behaviour rather than with words. It's not a very healthy way of sending a message, because people feel disrespected.¬†My guess is that your best bet is to be honest with mom, stop the sneaking around and come up with a detailed plan of how you're going to earn your freedom...eventually. She might listen to that.\n",
            "\n",
            "ü§ñ DPO Generated: It sounds like you're going through an incredibly difficult time right now, and it's completely understandable that you're feeling torn between your feelings for this person and the expectations of your mother. It takes a lot of courage to navigate these complex emotions.\n",
            "\n",
            "Firstly, I want to acknowledge how painful it is to feel like you've lost something precious in your life ‚Äì happiness and connection with someone you care about deeply. It‚Äôs natural to grieve when things change suddenly, especially when it involves relationships.\n",
            "\n",
            "Let's explore some options together. How do you feel about having open conversations with your mom? Perhaps explaining how seeing him at school affects you emotionally could help her understand the impact on your well-being. Additionally, you might consider expressing your concerns about honesty and trust within your family dynamic. Sometimes sharing our true feelings can create more understanding and potentially lead to compromise or finding alternative solutions.\n",
            "\n",
            "If direct communication feels too challenging, it might be worth considering other ways to cope with this situation. Have you tried journaling about your thoughts and feelings regarding this situation? Exploring your emotions on paper can sometimes provide clarity and serve as a release.\n",
            "\n",
            "Lastly, it's important to prioritize self-care during this time. Finding healthy outlets for your emotions, such as physical exercise, creative activities, or spending time with supportive friends, can help alleviate stress and maintain your overall well-being.\n",
            "\n",
            "Remember, it‚Äôs okay to ask for support and navigate this situation at your own pace. You deserve to find a balance that respects your feelings while\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "=== Test Sample 10 ===\n",
            "üí¨ Context: I know that I need to get past my feelings for this person I fell in love with, but t's so difficult to move on because he showed me feelings I've never felt before.    I feel like I don't want to be without my genuine love for him, but logically, I know I need to be without him. I can't discuss this with anybody in my life because the conditions surrounding our love are considered \"wrong\" by a lot of people.\n",
            "   How can I get myself to just move on?\n",
            "\n",
            "üìù Expected: There is no wrong or right way to define a relationship. I believe each relationship we are in is an opportunity to expand and to know self on a deeper level. We are conditioned to believe that we are not valued, or worth much without the confirmation of others and the world around us.¬†Give yourself time and try to not go to those who are toxic and enjoy the drama of others lives as s way to avoid looking at themselves.\n",
            "\n",
            "ü§ñ DPO Generated: It sounds like you're going through an incredibly challenging and emotional process right now, and it's completely understandable that you're feeling torn between your desire to hold onto those deep feelings and knowing what is best for your well-being. It takes immense courage to acknowledge the complexity of your emotions and to recognize when something isn't serving you positively.\n",
            "\n",
            "Firstly, let's validate how difficult it must be for you to navigate these conflicting emotions while also facing societal judgment or disapproval from others. Sometimes, we feel pressure to conform to certain expectations or norms, which can make moving forward even more complicated. \n",
            "\n",
            "Remember that it's okay to grieve the loss of a relationship, especially one that brought out such strong emotions within you. You deserve to honor those feelings rather than suppressing them. It might help to find healthy outlets for processing these emotions, whether through journaling, talking to yourself (if that feels comfortable), engaging in creative activities, or seeking support through online communities where acceptance may feel more present.\n",
            "\n",
            "When considering moving forward, try to focus on self-compassion and self-care. Treat yourself with kindness and understanding as you go through this transition. Explore new interests, hobbies, or social connections that bring you joy and fulfillment outside of this relationship. Building a sense of independence and growth will gradually help create space for new experiences and relationships.\n",
            "\n",
            "While it may not be possible to discuss this openly with everyone around you due to external factors, consider finding someone who is supportive and non-judgmental whom you\n",
            "--------------------------------------------------------------------------------\n",
            "\n",
            "üìà RESPONSE STATISTICS:\n",
            "   ‚Ä¢ Average response length: 1592.5 characters\n",
            "   ‚Ä¢ Shortest response: 1422 characters\n",
            "   ‚Ä¢ Longest response: 1711 characters\n",
            "   ‚Ä¢ Total responses: 10\n",
            "\n",
            "üéØ Run the next code block for comprehensive summary and final results!\n"
          ]
        }
      ],
      "source": [
        "# üìä DPO RESULTS VIEWER - Part 1: Display Test Results\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üìä LOADING DPO TEST RESULTS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Find the most recent test results file\n",
        "dpo_model_path = \"/content/drive/MyDrive/llama_31_therapist_outputs/dpo_therapy_model\"\n",
        "\n",
        "# Look for test results files\n",
        "test_files = [f for f in os.listdir(dpo_model_path) if f.startswith('test_responses_dpo_') and f.endswith('.json')]\n",
        "\n",
        "if test_files:\n",
        "    # Get the most recent file\n",
        "    latest_file = sorted(test_files)[-1]\n",
        "    results_file = f\"{dpo_model_path}/{latest_file}\"\n",
        "    print(f\"üìÅ Loading results from: {latest_file}\")\n",
        "else:\n",
        "    print(\"‚ùå No test results files found!\")\n",
        "    print(\"üîç Please run the testing code block first.\")\n",
        "    exit()\n",
        "\n",
        "# Read and display the results\n",
        "with open(results_file, 'r', encoding='utf-8') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "print(f\"üìä Found {len(data)} test responses\")\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"üß™ DPO MODEL TEST RESULTS\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Display each test result\n",
        "for i, response in enumerate(data):\n",
        "    print(f\"\\n=== Test Sample {response['sample_id']} ===\")\n",
        "    print(f\"üí¨ Context: {response['context']}\")\n",
        "\n",
        "    if response['expected_response']:\n",
        "        print(f\"\\nüìù Expected: {response['expected_response']}\")\n",
        "\n",
        "    print(f\"\\nü§ñ DPO Generated: {response['generated_response']}\")\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "# Calculate some basic stats\n",
        "response_lengths = [len(resp['generated_response']) for resp in data]\n",
        "avg_length = sum(response_lengths) / len(response_lengths)\n",
        "\n",
        "print(f\"\\nüìà RESPONSE STATISTICS:\")\n",
        "print(f\"   ‚Ä¢ Average response length: {avg_length:.1f} characters\")\n",
        "print(f\"   ‚Ä¢ Shortest response: {min(response_lengths)} characters\")\n",
        "print(f\"   ‚Ä¢ Longest response: {max(response_lengths)} characters\")\n",
        "print(f\"   ‚Ä¢ Total responses: {len(data)}\")\n",
        "\n",
        "print(\"\\nüéØ Run the next code block for comprehensive summary and final results!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXtG9Cjwj0CO",
        "outputId": "6ba9d9f5-1a92-4f26-8740-3bcc6a959c0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "üìä GENERATING DPO SUMMARY\n",
            "============================================================\n",
            "üíæ Summary saved to: /content/drive/MyDrive/llama_31_therapist_outputs/dpo_therapy_model/dpo_accurate_summary_20250629_163956.json\n",
            "\n",
            "============================================================\n",
            "üèÜ DPO METRICS\n",
            "============================================================\n",
            "üìä TRAINING:\n",
            "   ‚Ä¢ Train Loss: 0.0443\n",
            "   ‚Ä¢ Eval Loss: 0.05381\n",
            "   ‚Ä¢ Train Accuracy: 100.000%\n",
            "   ‚Ä¢ Eval Accuracy: 98.571%\n",
            "   ‚Ä¢ Train Reward Margins: 12.61265\n",
            "   ‚Ä¢ Eval Reward Margins: 10.81548\n",
            "   ‚Ä¢ Epochs: 3\n",
            "   ‚Ä¢ Steps: 1182\n",
            "   ‚Ä¢ Runtime: 3.08 hours\n",
            "\n",
            "üß™ TESTING:\n",
            "   ‚Ä¢ Test Samples: 10\n",
            "   ‚Ä¢ Avg Response Length: 1592.5 chars\n",
            "   ‚Ä¢ Min Response Length: 1422 chars\n",
            "   ‚Ä¢ Max Response Length: 1711 chars\n",
            "\n",
            "‚öôÔ∏è MODEL:\n",
            "   ‚Ä¢ Total Parameters: 4,624,486,400\n",
            "   ‚Ä¢ Trainable Parameters: 83,886,080\n",
            "   ‚Ä¢ GPU Memory: 42.47 GB\n",
            "============================================================\n"
          ]
        }
      ],
      "source": [
        "# üìä DPO RESULTS SUMMARY - Accurate Metrics\n",
        "import json\n",
        "import os\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"üìä GENERATING DPO SUMMARY\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Find the most recent test results file\n",
        "dpo_model_path = \"/content/drive/MyDrive/llama_31_therapist_outputs/dpo_therapy_model\"\n",
        "test_files = [f for f in os.listdir(dpo_model_path) if f.startswith('test_responses_dpo_') and f.endswith('.json')]\n",
        "\n",
        "if test_files:\n",
        "    latest_file = sorted(test_files)[-1]\n",
        "    results_file = f\"{dpo_model_path}/{latest_file}\"\n",
        "\n",
        "    with open(results_file, 'r', encoding='utf-8') as f:\n",
        "        data = json.load(f)\n",
        "\n",
        "    response_lengths = [len(resp['generated_response']) for resp in data]\n",
        "    avg_length = sum(response_lengths) / len(response_lengths)\n",
        "else:\n",
        "    print(\"‚ùå No test results found\")\n",
        "    exit()\n",
        "\n",
        "# Accurate metrics from W&B\n",
        "summary = {\n",
        "    'model': 'Llama-3.1-8B-DPO-Therapist',\n",
        "    'timestamp': datetime.now().isoformat(),\n",
        "    'test_samples': len(data),\n",
        "    'average_response_length': avg_length,\n",
        "    'min_response_length': min(response_lengths),\n",
        "    'max_response_length': max(response_lengths),\n",
        "    'model_path': dpo_model_path,\n",
        "\n",
        "    'dpo_metrics': {\n",
        "        'train_loss': 0.0443,\n",
        "        'eval_loss': 0.05381,\n",
        "        'train_accuracy': 1.0,\n",
        "        'eval_accuracy': 0.98571,\n",
        "        'train_reward_margins': 12.61265,\n",
        "        'eval_reward_margins': 10.81548,\n",
        "        'epochs': 3,\n",
        "        'global_steps': 1182,\n",
        "        'training_samples': 3500,\n",
        "        'total_parameters': 4624486400,\n",
        "        'trainable_parameters': 83886080,\n",
        "        'train_runtime_hours': 3.0802,\n",
        "        'gpu_memory_gb': 42.47447\n",
        "    }\n",
        "}\n",
        "\n",
        "# Save summary\n",
        "summary_file = f\"{dpo_model_path}/dpo_accurate_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "with open(summary_file, 'w') as f:\n",
        "    json.dump(summary, f, indent=2)\n",
        "\n",
        "print(f\"üíæ Summary saved to: {summary_file}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"üèÜ DPO METRICS\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "print(f\"üìä TRAINING:\")\n",
        "print(f\"   ‚Ä¢ Train Loss: {summary['dpo_metrics']['train_loss']}\")\n",
        "print(f\"   ‚Ä¢ Eval Loss: {summary['dpo_metrics']['eval_loss']}\")\n",
        "print(f\"   ‚Ä¢ Train Accuracy: {summary['dpo_metrics']['train_accuracy']*100:.3f}%\")\n",
        "print(f\"   ‚Ä¢ Eval Accuracy: {summary['dpo_metrics']['eval_accuracy']*100:.3f}%\")\n",
        "print(f\"   ‚Ä¢ Train Reward Margins: {summary['dpo_metrics']['train_reward_margins']}\")\n",
        "print(f\"   ‚Ä¢ Eval Reward Margins: {summary['dpo_metrics']['eval_reward_margins']}\")\n",
        "print(f\"   ‚Ä¢ Epochs: {summary['dpo_metrics']['epochs']}\")\n",
        "print(f\"   ‚Ä¢ Steps: {summary['dpo_metrics']['global_steps']}\")\n",
        "print(f\"   ‚Ä¢ Runtime: {summary['dpo_metrics']['train_runtime_hours']:.2f} hours\")\n",
        "\n",
        "print(f\"\\nüß™ TESTING:\")\n",
        "print(f\"   ‚Ä¢ Test Samples: {summary['test_samples']}\")\n",
        "print(f\"   ‚Ä¢ Avg Response Length: {summary['average_response_length']:.1f} chars\")\n",
        "print(f\"   ‚Ä¢ Min Response Length: {summary['min_response_length']} chars\")\n",
        "print(f\"   ‚Ä¢ Max Response Length: {summary['max_response_length']} chars\")\n",
        "\n",
        "print(f\"\\n‚öôÔ∏è MODEL:\")\n",
        "print(f\"   ‚Ä¢ Total Parameters: {summary['dpo_metrics']['total_parameters']:,}\")\n",
        "print(f\"   ‚Ä¢ Trainable Parameters: {summary['dpo_metrics']['trainable_parameters']:,}\")\n",
        "print(f\"   ‚Ä¢ GPU Memory: {summary['dpo_metrics']['gpu_memory_gb']:.2f} GB\")\n",
        "\n",
        "print(\"=\" * 60)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
